{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from glob import glob\n",
    "sys.path.append('../../src')\n",
    "sys.path.append('../../')\n",
    "import classifier.Multiband as multiband\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the filtering of the times must be done in the spine, not in each band. Spit all the times then slect the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:09:28.226200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.226605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.234698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.235005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.235270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.235526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# To see if the system regognises the GPU\n",
    "device = 0\n",
    "devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(devices[device], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=devices[device], enable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the different folds and train a model using the stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_CreateRecords/Folds/Fold_1/',\n",
       " '../02_CreateRecords/Folds/Fold_2/',\n",
       " '../02_CreateRecords/Folds/Fold_3/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = 'Gaia'\n",
    "path = os.path.join('../02_CreateRecords/Folds/Fold_*/',)\n",
    "folds = glob(path)\n",
    "folds.sort()\n",
    "folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./Results'):\n",
    "    os.mkdir('./Results')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the arguments for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_args = {\n",
    "            'hidden_size_bands':[128, 128, 128],\n",
    "            'hidden_size_central':[128, 128],\n",
    "            'fc_layers_bands':[128,128,128],\n",
    "            'fc_layers_central':[128,128,128], # Neurons of each layer\n",
    "            'regression_size':[128, 128],#each element is a layer with that size.\n",
    "            'buffer_size':10000,\n",
    "            'epochs':5,\n",
    "            'num_threads':7,\n",
    "            'batch_size':1024,\n",
    "            'dropout':0.40,\n",
    "            'lr':[[1e-3]*2, 1e-3], # [[band1, band2], central]\n",
    "            'val_steps':50,\n",
    "            'max_to_keep':0, # Not Used \n",
    "            'steps_wait':0, \n",
    "            'use_class_weights':False,# Not Used\n",
    "            'mode' : 'classifier+regression'\n",
    "            }\n",
    "loss_weights = {'Class':300.0, 'T_eff':20.0,'Radius':1e0}\n",
    "\n",
    "callbacks_args = {'patience': 20,\n",
    "                  'mode':'max',\n",
    "                  'restore_best_weights':True,\n",
    "                  'min_delta': 0.001\n",
    "                 }\n",
    "train_args_specific={\n",
    "                    'phys_params': ['T_eff', 'Radius'],\n",
    "                    'use_output_bands' : True,  # Working\n",
    "                    'use_output_central' : False, # Not used\n",
    "                    'use_common_layers' : False, # NOT Working\n",
    "                    'bidirectional_central' : False,# Working\n",
    "                    'bidirectional_band' : False,# Not Working\n",
    "                    'layer_norm_params' : None, # Used to normalyze common layers\n",
    "                    'use_gated_common' : False, # Working\n",
    "                    'l1':0.0,\n",
    "                    'l2':0.0,   \n",
    "                    'N_skip' : 8, # Cannot be greater than the number of timesteps\n",
    "                    'use_raw_input_central': True,\n",
    "                    'train_steps_central' : 2,\n",
    "                    'print_report' : True,\n",
    "                    'loss_weights_central' : loss_weights,\n",
    "                    'callbacks_args':callbacks_args\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:09:28.270574: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 12:09:28.270923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.271120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.271257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.636868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.637056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.637198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-07 12:09:28.637324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5686 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Results/Fold_1/Models/20230707-1209\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "input_LC_tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_LC_tf.Tensor(0, shape=(), dtype=int32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m test_files \u001b[38;5;241m=\u001b[39m base_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/*.tfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m new \u001b[38;5;241m=\u001b[39m multiband\u001b[38;5;241m.\u001b[39mNetwork()    \n\u001b[0;32m---> 23\u001b[0m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m new\u001b[38;5;241m.\u001b[39mtrain_loop()\n",
      "File \u001b[0;32m~/Dropbox/MyPythonClasses/Github/MultibandScalable_RNN/notebooks/03_TrainModels/../../src/classifier/Multiband.py:392\u001b[0m, in \u001b[0;36mNetwork.train\u001b[0;34m(self, train_args, tfrecords_train, tfrecords_val, tfrecords_test)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_placeholders()\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_writers()\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__add_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_callbacks()\n",
      "File \u001b[0;32m~/Dropbox/MyPythonClasses/Github/MultibandScalable_RNN/notebooks/03_TrainModels/../../src/classifier/Multiband.py:376\u001b[0m, in \u001b[0;36mNetwork.__add_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Add band models\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bands):\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__add_model_band\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Add spine model\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_model_central()\n",
      "File \u001b[0;32m~/Dropbox/MyPythonClasses/Github/MultibandScalable_RNN/notebooks/03_TrainModels/../../src/classifier/Multiband.py:46\u001b[0m, in \u001b[0;36mNetwork.__add_model_band\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_LC_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m---> 46\u001b[0m mean_mags \u001b[38;5;241m=\u001b[39m mean_mag(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_LC_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     47\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)],\n\u001b[1;32m     48\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM0_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)],\n\u001b[1;32m     49\u001b[0m                      )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Extract the raw times\u001b[39;00m\n\u001b[1;32m     51\u001b[0m RawTimes \u001b[38;5;241m=\u001b[39m RawTimesLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw,\n\u001b[1;32m     52\u001b[0m                          name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRawTimes_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i),\n\u001b[1;32m     53\u001b[0m                          )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_LC_tf.Tensor(0, shape=(), dtype=int32)'"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Set the fold path\n",
    "    base_dir = fold+'/'\n",
    "    \n",
    "    # Set the save path for this fold. Create folder if needed\n",
    "    path_results_fold = fold.replace('../02_CreateRecords', '.').replace('/Folds/', '/Results/')\n",
    "\n",
    "    if not os.path.exists(path_results_fold):\n",
    "        os.mkdir(path_results_fold)    \n",
    "\n",
    "    train_args_specific['save_dir'] = path_results_fold\n",
    "    train_args_specific['metadata_pre_path'] = base_dir+'metadata_preprocess.json'  \n",
    "    train_args_specific['path_scalers'] =  base_dir+'scalers.pkl'\n",
    "    # Define the train args\n",
    "    train_args = {**train_args, **train_args_specific}\n",
    "    \n",
    "    train_files = base_dir+'train/*.tfrecord'\n",
    "    val_files = base_dir+'val/*.tfrecord'\n",
    "    test_files = base_dir+'test/*.tfrecord'\n",
    "    \n",
    "    new = multiband.Network()    \n",
    "    new.train(train_args, train_files, val_files, test_files)\n",
    "    new.train_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'input_LC_0')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "new.inputs['input_LC_' + str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in new.dataset_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
