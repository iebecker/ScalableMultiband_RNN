{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c99e3d",
   "metadata": {},
   "source": [
    "Consolidate the folds into a single set of results.\n",
    "\n",
    "In particular, compute the mean and standard deviations of the models in the accuracy, recall and F-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0546de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 15:35:49.711131: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 15:35:49.711172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 15:35:49.712459: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 15:35:51.089614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Avoids warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ScalableLib.mixture.layers import create_models\n",
    "from ScalableLib.classifier import Multiband as multiband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4202927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# To see if the system recognises the GPU\n",
    "device = 1\n",
    "devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(devices[device], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=devices[device], enable=True)\n",
    "\n",
    "device_name = tf.config.experimental.get_device_details(devices[device])['device_name']\n",
    "print(\"Using {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30231379",
   "metadata": {},
   "source": [
    "Read the Results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffdc53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../02_CreateRecords/ZTF/Folds/Fold_1',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_2',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_3',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_4',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_5',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_6',\n",
       " '../../02_CreateRecords/ZTF/Folds/Fold_7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = 'ZTF'\n",
    "path = os.path.join('../../02_CreateRecords/', survey, 'Folds/Fold_*',)\n",
    "folds = glob(path)\n",
    "folds.sort()\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da83867",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./Results/'):\n",
    "    os.mkdir('./Results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc577db8",
   "metadata": {},
   "source": [
    "For each fold, read the models and evaluate on the test set. Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd63490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "            'hidden_size_bands':[128,128, 128],\n",
    "            'hidden_size_central':[128, 128],\n",
    "            'fc_layers_bands':[128,128,128],\n",
    "            'fc_layers_central':[128,128,128], # Neurons of each layer\n",
    "            'regression_size':[128, 128],#each element is a layer with that size.\n",
    "            'buffer_size':10000,\n",
    "            'epochs':1000,\n",
    "            'num_threads':7,\n",
    "            'batch_size':128,\n",
    "            'dropout':0.30,\n",
    "            'lr':[[5e-3]*2, 2.5e-3], # [[band1, band2], central]\n",
    "            'val_steps':50,\n",
    "            'max_to_keep':0, # Not Used \n",
    "            'steps_wait':500, \n",
    "            'use_class_weights':True,# Not Used as intended, for initialization\n",
    "            'mode' : 'classifier'\n",
    "            }\n",
    "loss_weights = {'Class':1.0}\n",
    "\n",
    "callbacks_args = {'patience': 20,\n",
    "                  'mode':'max',\n",
    "                  'restore_best_weights':True,\n",
    "                  'min_delta': 0.001\n",
    "                 }\n",
    "train_args_specific={\n",
    "                    'phys_params': [],\n",
    "                    'use_output_bands' : True,  # Working\n",
    "                    'use_output_central' : False, # Not used\n",
    "                    'use_common_layers' : False, # NOT Working\n",
    "                    'bidirectional_central' : False,# Working\n",
    "                    'bidirectional_band' : False,# Not Working\n",
    "                    'layer_norm_params' : None, # Used to normalyze common layers\n",
    "                    'use_gated_common' : False, # Working\n",
    "                    'l1':0.0,\n",
    "                    'l2':0.0,  \n",
    "                    'N_skip': 3, # Cannot be greater than the number of timesteps\n",
    "                    'use_raw_input_central': False,\n",
    "                    'train_steps_central' : 2,\n",
    "                    'print_report' : True,\n",
    "                    'loss_weights_central' : loss_weights,\n",
    "                    'callbacks_args':callbacks_args\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255e5e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Results/Fold_1/Models/20241002-1535\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727897808.125079   98190 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 74s 176ms/step - loss: 0.9222 - accuracy: 0.6984 - val_loss: 0.5945 - val_accuracy: 0.8014\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 37s 151ms/step - loss: 0.6149 - accuracy: 0.7965 - val_loss: 0.5277 - val_accuracy: 0.8209\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 35s 145ms/step - loss: 0.5280 - accuracy: 0.8223 - val_loss: 0.5110 - val_accuracy: 0.8250\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 35s 144ms/step - loss: 0.4931 - accuracy: 0.8320 - val_loss: 0.4582 - val_accuracy: 0.8417\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 35s 144ms/step - loss: 0.4513 - accuracy: 0.8463 - val_loss: 0.4139 - val_accuracy: 0.8556\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.4178 - accuracy: 0.8596 - val_loss: 0.3930 - val_accuracy: 0.8649\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.3872 - accuracy: 0.8690 - val_loss: 0.3669 - val_accuracy: 0.8737\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.3680 - accuracy: 0.8776 - val_loss: 0.3520 - val_accuracy: 0.8784\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 40s 166ms/step - loss: 0.3453 - accuracy: 0.8849 - val_loss: 0.3558 - val_accuracy: 0.8789\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 43s 178ms/step - loss: 0.3347 - accuracy: 0.8896 - val_loss: 0.3481 - val_accuracy: 0.8834\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 35s 145ms/step - loss: 0.3151 - accuracy: 0.8954 - val_loss: 0.3411 - val_accuracy: 0.8854\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 38s 157ms/step - loss: 0.3041 - accuracy: 0.9008 - val_loss: 0.3432 - val_accuracy: 0.8856\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 36s 147ms/step - loss: 0.2937 - accuracy: 0.9029 - val_loss: 0.3433 - val_accuracy: 0.8867\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.2803 - accuracy: 0.9077 - val_loss: 0.3395 - val_accuracy: 0.8891\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 40s 165ms/step - loss: 0.2725 - accuracy: 0.9104 - val_loss: 0.3402 - val_accuracy: 0.8854\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 38s 156ms/step - loss: 0.2655 - accuracy: 0.9134 - val_loss: 0.3395 - val_accuracy: 0.8869\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 38s 156ms/step - loss: 0.2567 - accuracy: 0.9162 - val_loss: 0.3398 - val_accuracy: 0.8899\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 37s 153ms/step - loss: 0.2558 - accuracy: 0.9172 - val_loss: 0.3447 - val_accuracy: 0.8860\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.2492 - accuracy: 0.9166 - val_loss: 0.3458 - val_accuracy: 0.8879\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.2426 - accuracy: 0.9217 - val_loss: 0.3432 - val_accuracy: 0.8885\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 35s 146ms/step - loss: 0.2415 - accuracy: 0.9225 - val_loss: 0.3446 - val_accuracy: 0.8893\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 40s 164ms/step - loss: 0.2391 - accuracy: 0.9217 - val_loss: 0.3451 - val_accuracy: 0.8910\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 49s 203ms/step - loss: 0.2410 - accuracy: 0.9217 - val_loss: 0.3460 - val_accuracy: 0.8908\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 52s 215ms/step - loss: 0.2354 - accuracy: 0.9233 - val_loss: 0.3451 - val_accuracy: 0.8897\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 50s 207ms/step - loss: 0.2374 - accuracy: 0.9245 - val_loss: 0.3463 - val_accuracy: 0.8897\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 60s 251ms/step - loss: 0.2290 - accuracy: 0.9258 - val_loss: 0.3457 - val_accuracy: 0.8906\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.2349 - accuracy: 0.9242 - val_loss: 0.3474 - val_accuracy: 0.8893\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.2280 - accuracy: 0.9276 - val_loss: 0.3478 - val_accuracy: 0.8891\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2328 - accuracy: 0.9250 - val_loss: 0.3486 - val_accuracy: 0.8895\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 60s 250ms/step - loss: 0.2311 - accuracy: 0.9263 - val_loss: 0.3488 - val_accuracy: 0.8912\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 60s 249ms/step - loss: 0.2292 - accuracy: 0.9264 - val_loss: 0.3491 - val_accuracy: 0.8906\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 60s 250ms/step - loss: 0.2304 - accuracy: 0.9265 - val_loss: 0.3484 - val_accuracy: 0.8897\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 56s 233ms/step - loss: 0.2312 - accuracy: 0.9261 - val_loss: 0.3490 - val_accuracy: 0.8906\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 57s 239ms/step - loss: 0.2309 - accuracy: 0.9265 - val_loss: 0.3497 - val_accuracy: 0.8906\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 59s 245ms/step - loss: 0.2278 - accuracy: 0.9262 - val_loss: 0.3496 - val_accuracy: 0.8908\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 58s 243ms/step - loss: 0.2271 - accuracy: 0.9263 - val_loss: 0.3495 - val_accuracy: 0.8906\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2252 - accuracy: 0.9269 - val_loss: 0.3499 - val_accuracy: 0.8908\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 61s 252ms/step - loss: 0.2274 - accuracy: 0.9273 - val_loss: 0.3499 - val_accuracy: 0.8908\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2295 - accuracy: 0.9245 - val_loss: 0.3497 - val_accuracy: 0.8906\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 55s 228ms/step - loss: 0.2268 - accuracy: 0.9263 - val_loss: 0.3500 - val_accuracy: 0.8910\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 55s 230ms/step - loss: 0.2268 - accuracy: 0.9268 - val_loss: 0.3500 - val_accuracy: 0.8910\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 54s 225ms/step - loss: 0.2306 - accuracy: 0.9255 - val_loss: 0.3501 - val_accuracy: 0.8912\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 54s 225ms/step - loss: 0.2251 - accuracy: 0.9278 - val_loss: 0.3501 - val_accuracy: 0.8908\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 54s 225ms/step - loss: 0.2275 - accuracy: 0.9271 - val_loss: 0.3501 - val_accuracy: 0.8910\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 56s 232ms/step - loss: 0.2264 - accuracy: 0.9276 - val_loss: 0.3501 - val_accuracy: 0.8910\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 56s 232ms/step - loss: 0.2259 - accuracy: 0.9262 - val_loss: 0.3501 - val_accuracy: 0.8910\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 57s 236ms/step - loss: 0.2272 - accuracy: 0.9266 - val_loss: 0.3502 - val_accuracy: 0.8912\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 60s 251ms/step - loss: 0.2292 - accuracy: 0.9244 - val_loss: 0.3502 - val_accuracy: 0.8908\n",
      "./Results/Fold_2/Models/20241002-1616\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 88s 277ms/step - loss: 0.9480 - accuracy: 0.6833 - val_loss: 0.6035 - val_accuracy: 0.7977\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.6428 - accuracy: 0.7827 - val_loss: 0.5267 - val_accuracy: 0.8199\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 61s 255ms/step - loss: 0.5503 - accuracy: 0.8140 - val_loss: 0.4713 - val_accuracy: 0.8423\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.4943 - accuracy: 0.8318 - val_loss: 0.4314 - val_accuracy: 0.8509\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.4496 - accuracy: 0.8460 - val_loss: 0.3956 - val_accuracy: 0.8696\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.4171 - accuracy: 0.8565 - val_loss: 0.3881 - val_accuracy: 0.8723\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3939 - accuracy: 0.8667 - val_loss: 0.3741 - val_accuracy: 0.8754\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 58s 239ms/step - loss: 0.3655 - accuracy: 0.8743 - val_loss: 0.3627 - val_accuracy: 0.8811\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 60s 250ms/step - loss: 0.3495 - accuracy: 0.8803 - val_loss: 0.3485 - val_accuracy: 0.8858\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 61s 251ms/step - loss: 0.3371 - accuracy: 0.8871 - val_loss: 0.3550 - val_accuracy: 0.8862\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 58s 241ms/step - loss: 0.3162 - accuracy: 0.8934 - val_loss: 0.3476 - val_accuracy: 0.8844\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 56s 231ms/step - loss: 0.3015 - accuracy: 0.8988 - val_loss: 0.3465 - val_accuracy: 0.8891\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 57s 237ms/step - loss: 0.2876 - accuracy: 0.9046 - val_loss: 0.3513 - val_accuracy: 0.8875\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 57s 236ms/step - loss: 0.2838 - accuracy: 0.9053 - val_loss: 0.3498 - val_accuracy: 0.8885\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 59s 246ms/step - loss: 0.2709 - accuracy: 0.9116 - val_loss: 0.3530 - val_accuracy: 0.8856\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 57s 237ms/step - loss: 0.2688 - accuracy: 0.9123 - val_loss: 0.3553 - val_accuracy: 0.8862\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2607 - accuracy: 0.9150 - val_loss: 0.3587 - val_accuracy: 0.8867\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 58s 239ms/step - loss: 0.2507 - accuracy: 0.9180 - val_loss: 0.3632 - val_accuracy: 0.8883\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 57s 236ms/step - loss: 0.2503 - accuracy: 0.9166 - val_loss: 0.3604 - val_accuracy: 0.8869\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 57s 235ms/step - loss: 0.2446 - accuracy: 0.9205 - val_loss: 0.3622 - val_accuracy: 0.8873\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2408 - accuracy: 0.9204 - val_loss: 0.3642 - val_accuracy: 0.8881\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 59s 246ms/step - loss: 0.2388 - accuracy: 0.9221 - val_loss: 0.3659 - val_accuracy: 0.8871\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 59s 245ms/step - loss: 0.2393 - accuracy: 0.9234 - val_loss: 0.3676 - val_accuracy: 0.8889\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 58s 240ms/step - loss: 0.2323 - accuracy: 0.9246 - val_loss: 0.3689 - val_accuracy: 0.8873\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 59s 245ms/step - loss: 0.2310 - accuracy: 0.9256 - val_loss: 0.3704 - val_accuracy: 0.8869\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 56s 233ms/step - loss: 0.2320 - accuracy: 0.9241 - val_loss: 0.3703 - val_accuracy: 0.8877\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 57s 235ms/step - loss: 0.2295 - accuracy: 0.9265 - val_loss: 0.3703 - val_accuracy: 0.8865\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 57s 237ms/step - loss: 0.2293 - accuracy: 0.9255 - val_loss: 0.3706 - val_accuracy: 0.8873\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 60s 248ms/step - loss: 0.2312 - accuracy: 0.9249 - val_loss: 0.3710 - val_accuracy: 0.8873\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2289 - accuracy: 0.9261 - val_loss: 0.3714 - val_accuracy: 0.8871\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 62s 255ms/step - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.3718 - val_accuracy: 0.8879\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 60s 248ms/step - loss: 0.2261 - accuracy: 0.9261 - val_loss: 0.3721 - val_accuracy: 0.8883\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 56s 233ms/step - loss: 0.2307 - accuracy: 0.9253 - val_loss: 0.3723 - val_accuracy: 0.8883\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2267 - accuracy: 0.9266 - val_loss: 0.3726 - val_accuracy: 0.8887\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 60s 249ms/step - loss: 0.2263 - accuracy: 0.9277 - val_loss: 0.3724 - val_accuracy: 0.8877\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 61s 252ms/step - loss: 0.2281 - accuracy: 0.9257 - val_loss: 0.3725 - val_accuracy: 0.8875\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 58s 242ms/step - loss: 0.2265 - accuracy: 0.9263 - val_loss: 0.3725 - val_accuracy: 0.8875\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 60s 249ms/step - loss: 0.2259 - accuracy: 0.9261 - val_loss: 0.3725 - val_accuracy: 0.8877\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2248 - accuracy: 0.9285 - val_loss: 0.3726 - val_accuracy: 0.8883\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 60s 251ms/step - loss: 0.2300 - accuracy: 0.9258 - val_loss: 0.3726 - val_accuracy: 0.8879\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.2299 - accuracy: 0.9257 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 59s 246ms/step - loss: 0.2235 - accuracy: 0.9272 - val_loss: 0.3727 - val_accuracy: 0.8883\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.2278 - accuracy: 0.9263 - val_loss: 0.3727 - val_accuracy: 0.8883\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 61s 252ms/step - loss: 0.2262 - accuracy: 0.9277 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2276 - accuracy: 0.9261 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 59s 244ms/step - loss: 0.2285 - accuracy: 0.9276 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 60s 249ms/step - loss: 0.2219 - accuracy: 0.9287 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 61s 253ms/step - loss: 0.2290 - accuracy: 0.9263 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 49/300\n",
      "241/241 [==============================] - 60s 251ms/step - loss: 0.2274 - accuracy: 0.9268 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 50/300\n",
      "241/241 [==============================] - 60s 249ms/step - loss: 0.2216 - accuracy: 0.9284 - val_loss: 0.3727 - val_accuracy: 0.8881\n",
      "Epoch 51/300\n",
      "241/241 [==============================] - 60s 250ms/step - loss: 0.2237 - accuracy: 0.9279 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 52/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2250 - accuracy: 0.9281 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 53/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2264 - accuracy: 0.9280 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 54/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2263 - accuracy: 0.9268 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 55/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2260 - accuracy: 0.9267 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 56/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2260 - accuracy: 0.9260 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 57/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2245 - accuracy: 0.9284 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 58/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2264 - accuracy: 0.9273 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 59/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2290 - accuracy: 0.9246 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "./Results/Fold_3/Models/20241002-1716\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 91s 292ms/step - loss: 0.9980 - accuracy: 0.6696 - val_loss: 0.6332 - val_accuracy: 0.7865\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.6232 - accuracy: 0.7918 - val_loss: 0.5092 - val_accuracy: 0.8263\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.5898 - accuracy: 0.8006 - val_loss: 0.4635 - val_accuracy: 0.8429\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.5062 - accuracy: 0.8265 - val_loss: 0.4372 - val_accuracy: 0.8452\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 64s 266ms/step - loss: 0.4655 - accuracy: 0.8429 - val_loss: 0.4103 - val_accuracy: 0.8554\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 64s 264ms/step - loss: 0.4241 - accuracy: 0.8556 - val_loss: 0.3858 - val_accuracy: 0.8680\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.4161 - accuracy: 0.8615 - val_loss: 0.3787 - val_accuracy: 0.8708\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.3856 - accuracy: 0.8682 - val_loss: 0.3690 - val_accuracy: 0.8749\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.3645 - accuracy: 0.8786 - val_loss: 0.3553 - val_accuracy: 0.8735\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.3478 - accuracy: 0.8837 - val_loss: 0.3546 - val_accuracy: 0.8758\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.3363 - accuracy: 0.8882 - val_loss: 0.3332 - val_accuracy: 0.8828\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.3259 - accuracy: 0.8910 - val_loss: 0.3307 - val_accuracy: 0.8895\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.3142 - accuracy: 0.8957 - val_loss: 0.3246 - val_accuracy: 0.8887\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 64s 265ms/step - loss: 0.3016 - accuracy: 0.8986 - val_loss: 0.3255 - val_accuracy: 0.8854\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 64s 264ms/step - loss: 0.2963 - accuracy: 0.9015 - val_loss: 0.3212 - val_accuracy: 0.8869\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 64s 264ms/step - loss: 0.2911 - accuracy: 0.9006 - val_loss: 0.3215 - val_accuracy: 0.8877\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2831 - accuracy: 0.9065 - val_loss: 0.3206 - val_accuracy: 0.8887\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 63s 264ms/step - loss: 0.2821 - accuracy: 0.9064 - val_loss: 0.3231 - val_accuracy: 0.8889\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2755 - accuracy: 0.9089 - val_loss: 0.3211 - val_accuracy: 0.8889\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 64s 264ms/step - loss: 0.2725 - accuracy: 0.9105 - val_loss: 0.3210 - val_accuracy: 0.8904\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2735 - accuracy: 0.9091 - val_loss: 0.3212 - val_accuracy: 0.8891\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2684 - accuracy: 0.9122 - val_loss: 0.3228 - val_accuracy: 0.8875\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2613 - accuracy: 0.9145 - val_loss: 0.3211 - val_accuracy: 0.8903\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2652 - accuracy: 0.9126 - val_loss: 0.3221 - val_accuracy: 0.8910\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2634 - accuracy: 0.9124 - val_loss: 0.3215 - val_accuracy: 0.8899\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2589 - accuracy: 0.9145 - val_loss: 0.3222 - val_accuracy: 0.8899\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 64s 264ms/step - loss: 0.2602 - accuracy: 0.9148 - val_loss: 0.3223 - val_accuracy: 0.8908\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2635 - accuracy: 0.9148 - val_loss: 0.3223 - val_accuracy: 0.8904\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2557 - accuracy: 0.9166 - val_loss: 0.3225 - val_accuracy: 0.8908\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2600 - accuracy: 0.9139 - val_loss: 0.3232 - val_accuracy: 0.8899\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2590 - accuracy: 0.9164 - val_loss: 0.3229 - val_accuracy: 0.8893\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2576 - accuracy: 0.9143 - val_loss: 0.3230 - val_accuracy: 0.8893\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2596 - accuracy: 0.9151 - val_loss: 0.3230 - val_accuracy: 0.8893\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2561 - accuracy: 0.9159 - val_loss: 0.3229 - val_accuracy: 0.8899\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2527 - accuracy: 0.9186 - val_loss: 0.3229 - val_accuracy: 0.8899\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2547 - accuracy: 0.9158 - val_loss: 0.3229 - val_accuracy: 0.8903\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2549 - accuracy: 0.9164 - val_loss: 0.3230 - val_accuracy: 0.8903\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2557 - accuracy: 0.9144 - val_loss: 0.3229 - val_accuracy: 0.8903\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2560 - accuracy: 0.9152 - val_loss: 0.3230 - val_accuracy: 0.8906\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2525 - accuracy: 0.9184 - val_loss: 0.3230 - val_accuracy: 0.8903\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2573 - accuracy: 0.9147 - val_loss: 0.3230 - val_accuracy: 0.8901\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2543 - accuracy: 0.9175 - val_loss: 0.3230 - val_accuracy: 0.8904\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2548 - accuracy: 0.9176 - val_loss: 0.3231 - val_accuracy: 0.8901\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2551 - accuracy: 0.9164 - val_loss: 0.3231 - val_accuracy: 0.8901\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2576 - accuracy: 0.9170 - val_loss: 0.3230 - val_accuracy: 0.8903\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2567 - accuracy: 0.9160 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2559 - accuracy: 0.9154 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2553 - accuracy: 0.9157 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 49/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2541 - accuracy: 0.9171 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 50/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2551 - accuracy: 0.9153 - val_loss: 0.3231 - val_accuracy: 0.8901\n",
      "Epoch 51/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2566 - accuracy: 0.9148 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 52/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2545 - accuracy: 0.9164 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 53/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2569 - accuracy: 0.9139 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 54/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2568 - accuracy: 0.9165 - val_loss: 0.3231 - val_accuracy: 0.8903\n",
      "Epoch 55/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2557 - accuracy: 0.9159 - val_loss: 0.3231 - val_accuracy: 0.8901\n",
      "./Results/Fold_4/Models/20241002-1815\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 90s 285ms/step - loss: 0.9521 - accuracy: 0.6822 - val_loss: 0.6234 - val_accuracy: 0.7910\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.6113 - accuracy: 0.7940 - val_loss: 0.5006 - val_accuracy: 0.8273\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.5203 - accuracy: 0.8237 - val_loss: 0.4555 - val_accuracy: 0.8470\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.4756 - accuracy: 0.8386 - val_loss: 0.4143 - val_accuracy: 0.8612\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.4355 - accuracy: 0.8496 - val_loss: 0.3838 - val_accuracy: 0.8700\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.3999 - accuracy: 0.8616 - val_loss: 0.3605 - val_accuracy: 0.8801\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3855 - accuracy: 0.8693 - val_loss: 0.3620 - val_accuracy: 0.8801\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.3570 - accuracy: 0.8783 - val_loss: 0.3455 - val_accuracy: 0.8887\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3355 - accuracy: 0.8876 - val_loss: 0.3416 - val_accuracy: 0.8883\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3219 - accuracy: 0.8886 - val_loss: 0.3282 - val_accuracy: 0.8914\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.3036 - accuracy: 0.8979 - val_loss: 0.3313 - val_accuracy: 0.8914\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2958 - accuracy: 0.8997 - val_loss: 0.3316 - val_accuracy: 0.8920\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2834 - accuracy: 0.9035 - val_loss: 0.3287 - val_accuracy: 0.8961\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2741 - accuracy: 0.9095 - val_loss: 0.3309 - val_accuracy: 0.8918\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2682 - accuracy: 0.9115 - val_loss: 0.3313 - val_accuracy: 0.8957\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2588 - accuracy: 0.9153 - val_loss: 0.3321 - val_accuracy: 0.8940\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2541 - accuracy: 0.9149 - val_loss: 0.3349 - val_accuracy: 0.8938\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2462 - accuracy: 0.9194 - val_loss: 0.3340 - val_accuracy: 0.8942\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2390 - accuracy: 0.9215 - val_loss: 0.3388 - val_accuracy: 0.8928\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2366 - accuracy: 0.9216 - val_loss: 0.3384 - val_accuracy: 0.8922\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2350 - accuracy: 0.9224 - val_loss: 0.3409 - val_accuracy: 0.8932\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2319 - accuracy: 0.9231 - val_loss: 0.3414 - val_accuracy: 0.8922\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2330 - accuracy: 0.9227 - val_loss: 0.3426 - val_accuracy: 0.8926\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2266 - accuracy: 0.9256 - val_loss: 0.3432 - val_accuracy: 0.8928\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2268 - accuracy: 0.9247 - val_loss: 0.3428 - val_accuracy: 0.8928\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2250 - accuracy: 0.9265 - val_loss: 0.3430 - val_accuracy: 0.8928\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2298 - accuracy: 0.9250 - val_loss: 0.3432 - val_accuracy: 0.8930\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2227 - accuracy: 0.9286 - val_loss: 0.3433 - val_accuracy: 0.8926\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2234 - accuracy: 0.9272 - val_loss: 0.3442 - val_accuracy: 0.8916\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2202 - accuracy: 0.9283 - val_loss: 0.3442 - val_accuracy: 0.8924\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2245 - accuracy: 0.9267 - val_loss: 0.3449 - val_accuracy: 0.8936\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2243 - accuracy: 0.9246 - val_loss: 0.3449 - val_accuracy: 0.8924\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2209 - accuracy: 0.9286 - val_loss: 0.3450 - val_accuracy: 0.8930\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2212 - accuracy: 0.9274 - val_loss: 0.3453 - val_accuracy: 0.8936\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2253 - accuracy: 0.9259 - val_loss: 0.3455 - val_accuracy: 0.8940\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2214 - accuracy: 0.9268 - val_loss: 0.3455 - val_accuracy: 0.8932\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2237 - accuracy: 0.9260 - val_loss: 0.3457 - val_accuracy: 0.8926\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2226 - accuracy: 0.9274 - val_loss: 0.3457 - val_accuracy: 0.8926\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2227 - accuracy: 0.9268 - val_loss: 0.3457 - val_accuracy: 0.8926\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2229 - accuracy: 0.9260 - val_loss: 0.3457 - val_accuracy: 0.8926\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2242 - accuracy: 0.9273 - val_loss: 0.3457 - val_accuracy: 0.8928\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2198 - accuracy: 0.9285 - val_loss: 0.3458 - val_accuracy: 0.8930\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2172 - accuracy: 0.9275 - val_loss: 0.3458 - val_accuracy: 0.8928\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2216 - accuracy: 0.9291 - val_loss: 0.3459 - val_accuracy: 0.8928\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2230 - accuracy: 0.9274 - val_loss: 0.3459 - val_accuracy: 0.8930\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2221 - accuracy: 0.9273 - val_loss: 0.3459 - val_accuracy: 0.8930\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2199 - accuracy: 0.9289 - val_loss: 0.3459 - val_accuracy: 0.8930\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2211 - accuracy: 0.9276 - val_loss: 0.3459 - val_accuracy: 0.8928\n",
      "./Results/Fold_5/Models/20241002-1906\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 90s 284ms/step - loss: 0.8928 - accuracy: 0.7070 - val_loss: 0.5952 - val_accuracy: 0.7957\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.6034 - accuracy: 0.7972 - val_loss: 0.5011 - val_accuracy: 0.8277\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.5173 - accuracy: 0.8234 - val_loss: 0.4434 - val_accuracy: 0.8478\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.4649 - accuracy: 0.8429 - val_loss: 0.4098 - val_accuracy: 0.8565\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.4293 - accuracy: 0.8546 - val_loss: 0.3990 - val_accuracy: 0.8591\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.4087 - accuracy: 0.8630 - val_loss: 0.3767 - val_accuracy: 0.8739\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3820 - accuracy: 0.8713 - val_loss: 0.3580 - val_accuracy: 0.8805\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3561 - accuracy: 0.8792 - val_loss: 0.3606 - val_accuracy: 0.8793\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3375 - accuracy: 0.8856 - val_loss: 0.3405 - val_accuracy: 0.8881\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3240 - accuracy: 0.8916 - val_loss: 0.3384 - val_accuracy: 0.8883\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3072 - accuracy: 0.8963 - val_loss: 0.3347 - val_accuracy: 0.8940\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2964 - accuracy: 0.9033 - val_loss: 0.3358 - val_accuracy: 0.8903\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2865 - accuracy: 0.9046 - val_loss: 0.3389 - val_accuracy: 0.8922\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2767 - accuracy: 0.9085 - val_loss: 0.3380 - val_accuracy: 0.8918\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2692 - accuracy: 0.9122 - val_loss: 0.3360 - val_accuracy: 0.8959\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2615 - accuracy: 0.9144 - val_loss: 0.3394 - val_accuracy: 0.8942\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2507 - accuracy: 0.9187 - val_loss: 0.3397 - val_accuracy: 0.8943\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2459 - accuracy: 0.9194 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2429 - accuracy: 0.9207 - val_loss: 0.3439 - val_accuracy: 0.8936\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2395 - accuracy: 0.9218 - val_loss: 0.3454 - val_accuracy: 0.8949\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2369 - accuracy: 0.9226 - val_loss: 0.3446 - val_accuracy: 0.8961\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2350 - accuracy: 0.9252 - val_loss: 0.3445 - val_accuracy: 0.8969\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2309 - accuracy: 0.9257 - val_loss: 0.3476 - val_accuracy: 0.8961\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2276 - accuracy: 0.9250 - val_loss: 0.3467 - val_accuracy: 0.8963\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2291 - accuracy: 0.9260 - val_loss: 0.3491 - val_accuracy: 0.8953\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2265 - accuracy: 0.9262 - val_loss: 0.3489 - val_accuracy: 0.8955\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 62s 255ms/step - loss: 0.2264 - accuracy: 0.9269 - val_loss: 0.3484 - val_accuracy: 0.8969\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 62s 255ms/step - loss: 0.2232 - accuracy: 0.9285 - val_loss: 0.3490 - val_accuracy: 0.8967\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2270 - accuracy: 0.9271 - val_loss: 0.3496 - val_accuracy: 0.8969\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2224 - accuracy: 0.9290 - val_loss: 0.3502 - val_accuracy: 0.8969\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2230 - accuracy: 0.9287 - val_loss: 0.3498 - val_accuracy: 0.8957\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2250 - accuracy: 0.9286 - val_loss: 0.3504 - val_accuracy: 0.8969\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2221 - accuracy: 0.9297 - val_loss: 0.3501 - val_accuracy: 0.8965\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2217 - accuracy: 0.9295 - val_loss: 0.3503 - val_accuracy: 0.8967\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 61s 255ms/step - loss: 0.2240 - accuracy: 0.9287 - val_loss: 0.3504 - val_accuracy: 0.8965\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2221 - accuracy: 0.9293 - val_loss: 0.3506 - val_accuracy: 0.8967\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2209 - accuracy: 0.9287 - val_loss: 0.3509 - val_accuracy: 0.8963\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2220 - accuracy: 0.9292 - val_loss: 0.3509 - val_accuracy: 0.8965\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2231 - accuracy: 0.9282 - val_loss: 0.3509 - val_accuracy: 0.8965\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2196 - accuracy: 0.9293 - val_loss: 0.3509 - val_accuracy: 0.8969\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2219 - accuracy: 0.9292 - val_loss: 0.3510 - val_accuracy: 0.8965\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2259 - accuracy: 0.9283 - val_loss: 0.3509 - val_accuracy: 0.8969\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2221 - accuracy: 0.9282 - val_loss: 0.3509 - val_accuracy: 0.8965\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2247 - accuracy: 0.9276 - val_loss: 0.3509 - val_accuracy: 0.8969\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2207 - accuracy: 0.9295 - val_loss: 0.3509 - val_accuracy: 0.8969\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2196 - accuracy: 0.9292 - val_loss: 0.3510 - val_accuracy: 0.8971\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2223 - accuracy: 0.9286 - val_loss: 0.3510 - val_accuracy: 0.8971\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 61s 255ms/step - loss: 0.2217 - accuracy: 0.9286 - val_loss: 0.3510 - val_accuracy: 0.8971\n",
      "Epoch 49/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2233 - accuracy: 0.9284 - val_loss: 0.3510 - val_accuracy: 0.8969\n",
      "Epoch 50/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2178 - accuracy: 0.9297 - val_loss: 0.3510 - val_accuracy: 0.8969\n",
      "Epoch 51/300\n",
      "241/241 [==============================] - 61s 254ms/step - loss: 0.2208 - accuracy: 0.9293 - val_loss: 0.3510 - val_accuracy: 0.8969\n",
      "Epoch 52/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2192 - accuracy: 0.9306 - val_loss: 0.3510 - val_accuracy: 0.8971\n",
      "Epoch 53/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2181 - accuracy: 0.9294 - val_loss: 0.3510 - val_accuracy: 0.8971\n",
      "./Results/Fold_6/Models/20241002-2001\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 88s 285ms/step - loss: 0.9819 - accuracy: 0.6708 - val_loss: 0.5711 - val_accuracy: 0.7957\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.5979 - accuracy: 0.7995 - val_loss: 0.4913 - val_accuracy: 0.8278\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.5138 - accuracy: 0.8263 - val_loss: 0.4064 - val_accuracy: 0.8624\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.4670 - accuracy: 0.8404 - val_loss: 0.4029 - val_accuracy: 0.8567\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.4243 - accuracy: 0.8566 - val_loss: 0.3698 - val_accuracy: 0.8666\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3958 - accuracy: 0.8655 - val_loss: 0.3469 - val_accuracy: 0.8809\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.3697 - accuracy: 0.8754 - val_loss: 0.3420 - val_accuracy: 0.8844\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.3512 - accuracy: 0.8816 - val_loss: 0.3306 - val_accuracy: 0.8867\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3325 - accuracy: 0.8879 - val_loss: 0.3284 - val_accuracy: 0.8863\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3125 - accuracy: 0.8957 - val_loss: 0.3253 - val_accuracy: 0.8865\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3001 - accuracy: 0.8996 - val_loss: 0.3191 - val_accuracy: 0.8902\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2874 - accuracy: 0.9053 - val_loss: 0.3134 - val_accuracy: 0.8930\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2765 - accuracy: 0.9080 - val_loss: 0.3204 - val_accuracy: 0.8928\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2625 - accuracy: 0.9137 - val_loss: 0.3170 - val_accuracy: 0.8937\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2536 - accuracy: 0.9174 - val_loss: 0.3272 - val_accuracy: 0.8908\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2486 - accuracy: 0.9184 - val_loss: 0.3281 - val_accuracy: 0.8902\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2401 - accuracy: 0.9221 - val_loss: 0.3226 - val_accuracy: 0.8947\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2357 - accuracy: 0.9245 - val_loss: 0.3254 - val_accuracy: 0.8939\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2249 - accuracy: 0.9272 - val_loss: 0.3300 - val_accuracy: 0.8922\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2231 - accuracy: 0.9283 - val_loss: 0.3347 - val_accuracy: 0.8922\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2247 - accuracy: 0.9276 - val_loss: 0.3323 - val_accuracy: 0.8934\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2201 - accuracy: 0.9299 - val_loss: 0.3345 - val_accuracy: 0.8926\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2203 - accuracy: 0.9290 - val_loss: 0.3321 - val_accuracy: 0.8932\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2142 - accuracy: 0.9310 - val_loss: 0.3352 - val_accuracy: 0.8918\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2121 - accuracy: 0.9330 - val_loss: 0.3357 - val_accuracy: 0.8922\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2148 - accuracy: 0.9314 - val_loss: 0.3363 - val_accuracy: 0.8922\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2100 - accuracy: 0.9333 - val_loss: 0.3383 - val_accuracy: 0.8912\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2107 - accuracy: 0.9326 - val_loss: 0.3380 - val_accuracy: 0.8922\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2117 - accuracy: 0.9322 - val_loss: 0.3376 - val_accuracy: 0.8922\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2097 - accuracy: 0.9323 - val_loss: 0.3380 - val_accuracy: 0.8918\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2079 - accuracy: 0.9328 - val_loss: 0.3384 - val_accuracy: 0.8916\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2106 - accuracy: 0.9317 - val_loss: 0.3386 - val_accuracy: 0.8920\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2072 - accuracy: 0.9340 - val_loss: 0.3385 - val_accuracy: 0.8912\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2101 - accuracy: 0.9327 - val_loss: 0.3388 - val_accuracy: 0.8914\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2082 - accuracy: 0.9325 - val_loss: 0.3387 - val_accuracy: 0.8916\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2060 - accuracy: 0.9339 - val_loss: 0.3389 - val_accuracy: 0.8914\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2090 - accuracy: 0.9339 - val_loss: 0.3389 - val_accuracy: 0.8916\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2051 - accuracy: 0.9337 - val_loss: 0.3391 - val_accuracy: 0.8918\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2082 - accuracy: 0.9333 - val_loss: 0.3393 - val_accuracy: 0.8916\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2076 - accuracy: 0.9338 - val_loss: 0.3393 - val_accuracy: 0.8918\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2067 - accuracy: 0.9339 - val_loss: 0.3393 - val_accuracy: 0.8916\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2068 - accuracy: 0.9343 - val_loss: 0.3394 - val_accuracy: 0.8920\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2064 - accuracy: 0.9345 - val_loss: 0.3394 - val_accuracy: 0.8916\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2098 - accuracy: 0.9336 - val_loss: 0.3394 - val_accuracy: 0.8916\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2090 - accuracy: 0.9330 - val_loss: 0.3394 - val_accuracy: 0.8918\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2068 - accuracy: 0.9342 - val_loss: 0.3394 - val_accuracy: 0.8922\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2072 - accuracy: 0.9340 - val_loss: 0.3394 - val_accuracy: 0.8918\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2079 - accuracy: 0.9348 - val_loss: 0.3394 - val_accuracy: 0.8918\n",
      "Epoch 49/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2073 - accuracy: 0.9346 - val_loss: 0.3394 - val_accuracy: 0.8918\n",
      "Epoch 50/300\n",
      "241/241 [==============================] - 62s 255ms/step - loss: 0.2104 - accuracy: 0.9333 - val_loss: 0.3394 - val_accuracy: 0.8920\n",
      "Epoch 51/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2077 - accuracy: 0.9332 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 52/300\n",
      "241/241 [==============================] - 62s 255ms/step - loss: 0.2055 - accuracy: 0.9338 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 53/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2085 - accuracy: 0.9339 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 54/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2084 - accuracy: 0.9332 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 55/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2054 - accuracy: 0.9347 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 56/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2093 - accuracy: 0.9339 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 57/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2045 - accuracy: 0.9351 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 58/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2083 - accuracy: 0.9348 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 59/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2079 - accuracy: 0.9327 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 60/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2086 - accuracy: 0.9343 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 61/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2080 - accuracy: 0.9337 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "Epoch 62/300\n",
      "241/241 [==============================] - 62s 256ms/step - loss: 0.2089 - accuracy: 0.9343 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
      "./Results/Fold_7/Models/20241002-2107\n",
      "Epoch 1/300\n",
      "241/241 [==============================] - 91s 287ms/step - loss: 0.9506 - accuracy: 0.6882 - val_loss: 0.6135 - val_accuracy: 0.7863\n",
      "Epoch 2/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.6172 - accuracy: 0.7924 - val_loss: 0.4859 - val_accuracy: 0.8288\n",
      "Epoch 3/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.5291 - accuracy: 0.8172 - val_loss: 0.4393 - val_accuracy: 0.8468\n",
      "Epoch 4/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.4821 - accuracy: 0.8360 - val_loss: 0.4078 - val_accuracy: 0.8583\n",
      "Epoch 5/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.4492 - accuracy: 0.8461 - val_loss: 0.4013 - val_accuracy: 0.8579\n",
      "Epoch 6/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.4186 - accuracy: 0.8556 - val_loss: 0.3807 - val_accuracy: 0.8649\n",
      "Epoch 7/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.3939 - accuracy: 0.8675 - val_loss: 0.3542 - val_accuracy: 0.8803\n",
      "Epoch 8/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.3675 - accuracy: 0.8756 - val_loss: 0.3510 - val_accuracy: 0.8826\n",
      "Epoch 9/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.3537 - accuracy: 0.8830 - val_loss: 0.3386 - val_accuracy: 0.8815\n",
      "Epoch 10/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.3392 - accuracy: 0.8865 - val_loss: 0.3432 - val_accuracy: 0.8859\n",
      "Epoch 11/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.3240 - accuracy: 0.8924 - val_loss: 0.3388 - val_accuracy: 0.8838\n",
      "Epoch 12/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.3107 - accuracy: 0.8961 - val_loss: 0.3307 - val_accuracy: 0.8889\n",
      "Epoch 13/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2958 - accuracy: 0.9005 - val_loss: 0.3307 - val_accuracy: 0.8928\n",
      "Epoch 14/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2860 - accuracy: 0.9043 - val_loss: 0.3293 - val_accuracy: 0.8937\n",
      "Epoch 15/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2775 - accuracy: 0.9078 - val_loss: 0.3267 - val_accuracy: 0.8930\n",
      "Epoch 16/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2708 - accuracy: 0.9114 - val_loss: 0.3303 - val_accuracy: 0.8961\n",
      "Epoch 17/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2660 - accuracy: 0.9131 - val_loss: 0.3332 - val_accuracy: 0.8928\n",
      "Epoch 18/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2610 - accuracy: 0.9150 - val_loss: 0.3304 - val_accuracy: 0.8955\n",
      "Epoch 19/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2549 - accuracy: 0.9158 - val_loss: 0.3339 - val_accuracy: 0.8941\n",
      "Epoch 20/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2473 - accuracy: 0.9193 - val_loss: 0.3349 - val_accuracy: 0.8945\n",
      "Epoch 21/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2476 - accuracy: 0.9196 - val_loss: 0.3361 - val_accuracy: 0.8928\n",
      "Epoch 22/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2440 - accuracy: 0.9193 - val_loss: 0.3340 - val_accuracy: 0.8943\n",
      "Epoch 23/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2437 - accuracy: 0.9195 - val_loss: 0.3343 - val_accuracy: 0.8949\n",
      "Epoch 24/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2413 - accuracy: 0.9230 - val_loss: 0.3362 - val_accuracy: 0.8947\n",
      "Epoch 25/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2363 - accuracy: 0.9232 - val_loss: 0.3355 - val_accuracy: 0.8963\n",
      "Epoch 26/300\n",
      "241/241 [==============================] - 60s 251ms/step - loss: 0.2345 - accuracy: 0.9239 - val_loss: 0.3369 - val_accuracy: 0.8961\n",
      "Epoch 27/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2339 - accuracy: 0.9241 - val_loss: 0.3372 - val_accuracy: 0.8953\n",
      "Epoch 28/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2344 - accuracy: 0.9231 - val_loss: 0.3372 - val_accuracy: 0.8939\n",
      "Epoch 29/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2349 - accuracy: 0.9238 - val_loss: 0.3377 - val_accuracy: 0.8949\n",
      "Epoch 30/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2331 - accuracy: 0.9251 - val_loss: 0.3381 - val_accuracy: 0.8949\n",
      "Epoch 31/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2295 - accuracy: 0.9262 - val_loss: 0.3382 - val_accuracy: 0.8953\n",
      "Epoch 32/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2275 - accuracy: 0.9257 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 33/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2313 - accuracy: 0.9257 - val_loss: 0.3384 - val_accuracy: 0.8945\n",
      "Epoch 34/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2305 - accuracy: 0.9257 - val_loss: 0.3381 - val_accuracy: 0.8955\n",
      "Epoch 35/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2268 - accuracy: 0.9257 - val_loss: 0.3383 - val_accuracy: 0.8957\n",
      "Epoch 36/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2313 - accuracy: 0.9247 - val_loss: 0.3385 - val_accuracy: 0.8953\n",
      "Epoch 37/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2301 - accuracy: 0.9258 - val_loss: 0.3386 - val_accuracy: 0.8953\n",
      "Epoch 38/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2317 - accuracy: 0.9237 - val_loss: 0.3387 - val_accuracy: 0.8951\n",
      "Epoch 39/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2286 - accuracy: 0.9247 - val_loss: 0.3387 - val_accuracy: 0.8951\n",
      "Epoch 40/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2304 - accuracy: 0.9245 - val_loss: 0.3387 - val_accuracy: 0.8953\n",
      "Epoch 41/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2270 - accuracy: 0.9264 - val_loss: 0.3386 - val_accuracy: 0.8953\n",
      "Epoch 42/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2275 - accuracy: 0.9256 - val_loss: 0.3386 - val_accuracy: 0.8955\n",
      "Epoch 43/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2306 - accuracy: 0.9248 - val_loss: 0.3386 - val_accuracy: 0.8955\n",
      "Epoch 44/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2298 - accuracy: 0.9253 - val_loss: 0.3386 - val_accuracy: 0.8955\n",
      "Epoch 45/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2314 - accuracy: 0.9247 - val_loss: 0.3386 - val_accuracy: 0.8955\n",
      "Epoch 46/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2301 - accuracy: 0.9251 - val_loss: 0.3387 - val_accuracy: 0.8959\n",
      "Epoch 47/300\n",
      "241/241 [==============================] - 63s 263ms/step - loss: 0.2290 - accuracy: 0.9261 - val_loss: 0.3387 - val_accuracy: 0.8959\n",
      "Epoch 48/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2273 - accuracy: 0.9261 - val_loss: 0.3387 - val_accuracy: 0.8959\n",
      "Epoch 49/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2253 - accuracy: 0.9277 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 50/300\n",
      "241/241 [==============================] - 63s 262ms/step - loss: 0.2305 - accuracy: 0.9236 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 51/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2317 - accuracy: 0.9247 - val_loss: 0.3387 - val_accuracy: 0.8959\n",
      "Epoch 52/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2303 - accuracy: 0.9253 - val_loss: 0.3387 - val_accuracy: 0.8959\n",
      "Epoch 53/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2280 - accuracy: 0.9254 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 54/300\n",
      "241/241 [==============================] - 63s 261ms/step - loss: 0.2282 - accuracy: 0.9263 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 55/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2268 - accuracy: 0.9274 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 56/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2288 - accuracy: 0.9260 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 57/300\n",
      "241/241 [==============================] - 62s 257ms/step - loss: 0.2310 - accuracy: 0.9246 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 58/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2303 - accuracy: 0.9263 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 59/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2287 - accuracy: 0.9267 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 60/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2253 - accuracy: 0.9274 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 61/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2261 - accuracy: 0.9258 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 62/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2321 - accuracy: 0.9244 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 63/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2292 - accuracy: 0.9252 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 64/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2298 - accuracy: 0.9257 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 65/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2286 - accuracy: 0.9268 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 66/300\n",
      "241/241 [==============================] - 62s 258ms/step - loss: 0.2291 - accuracy: 0.9255 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 67/300\n",
      "241/241 [==============================] - 62s 259ms/step - loss: 0.2308 - accuracy: 0.9257 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 68/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2284 - accuracy: 0.9260 - val_loss: 0.3387 - val_accuracy: 0.8957\n",
      "Epoch 69/300\n",
      "241/241 [==============================] - 63s 260ms/step - loss: 0.2271 - accuracy: 0.9266 - val_loss: 0.3387 - val_accuracy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "sauces = []\n",
    "for fold in folds:\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Set the fold path\n",
    "    base_dir = fold+'/'\n",
    "    \n",
    "    # Set the save path for this fold. Create folder if needed\n",
    "    path_results_fold = fold.replace('../../02_CreateRecords/'+survey+'/', './').replace('/Folds/', '/Results/')\n",
    "    if not os.path.exists(path_results_fold):\n",
    "        os.mkdir(path_results_fold)    \n",
    "        \n",
    "    train_args_specific['save_dir'] = path_results_fold\n",
    "    train_args_specific['metadata_pre_path'] = base_dir+'metadata_preprocess.json'  \n",
    "    train_args_specific['path_scalers'] =  os.path.join(fold,'scalers.pkl')\n",
    "    # Define the train args\n",
    "    train_args = {**train_args, **train_args_specific}\n",
    "    \n",
    "    train_files = base_dir+'train/*.tfrecord'\n",
    "    val_files = base_dir+'val/*.tfrecord'\n",
    "    test_files = base_dir+'test/*.tfrecord'\n",
    "    \n",
    "    new = multiband.Network()    \n",
    "    new.train(train_args, train_files, val_files, test_files)\n",
    "    # Create the Mixture of Experts model, from the original multiband model\n",
    "    model_base = create_models(new)\n",
    "    model = model_base.creat_split_models(train_args)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='accuracy', **callbacks_args)\n",
    "    # Fit the model to the original data\n",
    "    model.fit(new.dataset_train, validation_data=new.dataset_val, epochs=300,callbacks = [es] )\n",
    "\n",
    "    # Store the alpha coefficients per fold\n",
    "    sauces_ = {i.name:i for i in model.layers if 'Sauce_' in i.name}\n",
    "    scales = {key:tf.nn.softmax(sauces_[key].scale).numpy() for key in sauces_.keys()}\n",
    "    sauces.append(scales)\n",
    "    # Test\n",
    "    dfs = []\n",
    "    for batch in new.dataset_test:\n",
    "        prediction = model(batch[0])\n",
    "        y_pred = prediction['Class'].numpy().argmax(axis=1)\n",
    "        y_pred = [new.trans[i] for i in y_pred]\n",
    "        ID = batch[0]['ID'].numpy()\n",
    "\n",
    "        y_true = batch[1]['Class'].numpy().argmax(axis=1)\n",
    "        y_true = [new.trans[i] for i in y_true]\n",
    "\n",
    "        df = pd.DataFrame(np.array([ID, y_pred, y_true]).transpose(), columns=['ID', 'Class', 'Pred'])\n",
    "        df.ID = df.ID.str.decode('UTF-8')\n",
    "        dfs.append(df)\n",
    "    dfs = pd.concat(dfs, axis=0)\n",
    "    dfs.to_csv(path_results_fold+'/Classification_test.dat', index=False, index_label=False)\n",
    "    \n",
    "pd.DataFrame(sauces).to_csv(path_results_fold+'/sauces.dat', index=False, index_label=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a31e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c607f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
