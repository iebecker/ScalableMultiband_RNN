{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 14:40:30.111333: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 14:40:30.111370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 14:40:30.112378: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 14:40:31.075006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Avoids warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ScalableLib.mixture.layers import create_models\n",
    "from ScalableLib.classifier import Multiband as multiband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier mode only should ignore physical parameters listed in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# To see if the system recognises the GPU\n",
    "device = 1\n",
    "devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(devices[device], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=devices[device], enable=True)\n",
    "\n",
    "device_name = tf.config.experimental.get_device_details(devices[device])['device_name']\n",
    "print(\"Using {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the different folds and train a model using the stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../02_CreateRecords/PanStarrs/Folds/Fold_1',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_2',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_3',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_4',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_5',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_6',\n",
       " '../../02_CreateRecords/PanStarrs/Folds/Fold_7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = 'PanStarrs'\n",
    "path = os.path.join('../../02_CreateRecords/', survey, 'Folds/Fold_*',)\n",
    "folds = glob(path)\n",
    "folds.sort()\n",
    "folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./Results'):\n",
    "    os.mkdir('./Results')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the arguments for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "            'hidden_size_bands':[64, 64, 64],\n",
    "            'hidden_size_central':[64, 64, 64],\n",
    "            'fc_layers_bands':[128,128],\n",
    "            'fc_layers_central':[128,128], # Neurons of each layer\n",
    "            'regression_size':[128, 128],#each element is a layer with that size.\n",
    "            'buffer_size':10000,\n",
    "            'epochs':1000,\n",
    "            'num_threads':7,\n",
    "            'batch_size':512,\n",
    "            'dropout':0.35,\n",
    "            'lr':[[5e-3]*5, 2.5e-3], # [[band1, band2], central]\n",
    "            'val_steps':50,\n",
    "            'max_to_keep':0, # Not Used \n",
    "            'steps_wait':500, \n",
    "            'use_class_weights':False,# Not Used\n",
    "            'mode' : 'classifier'\n",
    "            }\n",
    "loss_weights = {'Class':1.0}\n",
    "\n",
    "callbacks_args = {'patience': 20,\n",
    "                  'mode':'max',\n",
    "                  'restore_best_weights':True,\n",
    "                  'min_delta': 0.001\n",
    "                 }\n",
    "train_args_specific={\n",
    "                    'phys_params': [],\n",
    "                    'use_output_bands' : True,  # Working\n",
    "                    'use_output_central' : False, # Not used\n",
    "                    'use_common_layers' : False, # NOT Working\n",
    "                    'bidirectional_central' : False,# Working\n",
    "                    'bidirectional_band' : False,# Not Working\n",
    "                    'layer_norm_params' : None, # Used to normalyze common layers\n",
    "                    'use_gated_common' : False, # Working\n",
    "                    'l1':0.0,\n",
    "                    'l2':0.0,\n",
    "                    'N_skip' : 2, # Cannot be greater than the number of timesteps\n",
    "                    'use_raw_input_central': False,\n",
    "                    'train_steps_central' : 1,\n",
    "                    'print_report' : True,\n",
    "                    'loss_weights_central' : loss_weights,\n",
    "                    'callbacks_args':callbacks_args    \n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Results/Fold_1/Models/20241002-1440\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727894540.033931   30256 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 92s 688ms/step - loss: 1.0702 - accuracy: 0.5323 - val_loss: 0.8616 - val_accuracy: 0.5845\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.8918 - accuracy: 0.5884 - val_loss: 0.7822 - val_accuracy: 0.6447\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.7923 - accuracy: 0.6599 - val_loss: 0.7165 - val_accuracy: 0.6866\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.7161 - accuracy: 0.6942 - val_loss: 0.6530 - val_accuracy: 0.7226\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.6410 - accuracy: 0.7454 - val_loss: 0.5842 - val_accuracy: 0.7675\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5802 - accuracy: 0.7762 - val_loss: 0.5531 - val_accuracy: 0.7874\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5505 - accuracy: 0.7919 - val_loss: 0.5474 - val_accuracy: 0.7871\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5169 - accuracy: 0.8040 - val_loss: 0.5308 - val_accuracy: 0.7884\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.4941 - accuracy: 0.8167 - val_loss: 0.5062 - val_accuracy: 0.8114\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.4658 - accuracy: 0.8240 - val_loss: 0.5046 - val_accuracy: 0.8024\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.4456 - accuracy: 0.8385 - val_loss: 0.4987 - val_accuracy: 0.8100\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.4195 - accuracy: 0.8501 - val_loss: 0.4866 - val_accuracy: 0.8177\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.3894 - accuracy: 0.8596 - val_loss: 0.4970 - val_accuracy: 0.8300\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.3727 - accuracy: 0.8684 - val_loss: 0.5312 - val_accuracy: 0.8190\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.3441 - accuracy: 0.8807 - val_loss: 0.5170 - val_accuracy: 0.8234\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.3184 - accuracy: 0.8899 - val_loss: 0.5476 - val_accuracy: 0.8094\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.2921 - accuracy: 0.9021 - val_loss: 0.5661 - val_accuracy: 0.8187\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.2653 - accuracy: 0.9103 - val_loss: 0.5811 - val_accuracy: 0.8150\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.2477 - accuracy: 0.9186 - val_loss: 0.6421 - val_accuracy: 0.8061\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.2257 - accuracy: 0.9251 - val_loss: 0.6443 - val_accuracy: 0.8107\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.1989 - accuracy: 0.9340 - val_loss: 0.6961 - val_accuracy: 0.8090\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.1783 - accuracy: 0.9397 - val_loss: 0.7366 - val_accuracy: 0.8074\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.1550 - accuracy: 0.9507 - val_loss: 0.7728 - val_accuracy: 0.8041\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.1337 - accuracy: 0.9586 - val_loss: 0.8265 - val_accuracy: 0.8077\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.1316 - accuracy: 0.9578 - val_loss: 0.8743 - val_accuracy: 0.7991\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.1331 - accuracy: 0.9568 - val_loss: 0.8712 - val_accuracy: 0.8011\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1116 - accuracy: 0.9640 - val_loss: 0.9222 - val_accuracy: 0.7927\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0902 - accuracy: 0.9728 - val_loss: 0.9887 - val_accuracy: 0.7951\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0774 - accuracy: 0.9774 - val_loss: 1.0122 - val_accuracy: 0.8067\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0738 - accuracy: 0.9782 - val_loss: 1.0468 - val_accuracy: 0.7994\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 1.0881 - val_accuracy: 0.7944\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0668 - accuracy: 0.9786 - val_loss: 1.1037 - val_accuracy: 0.7947\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0566 - accuracy: 0.9825 - val_loss: 1.1632 - val_accuracy: 0.7967\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 1.1985 - val_accuracy: 0.7851\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 1.2015 - val_accuracy: 0.7941\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 1.2484 - val_accuracy: 0.7884\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 1.2369 - val_accuracy: 0.7997\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 1.3126 - val_accuracy: 0.7944\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 1.3437 - val_accuracy: 0.7934\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 1.3671 - val_accuracy: 0.7927\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 1.3736 - val_accuracy: 0.7901\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 1.3906 - val_accuracy: 0.7884\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 1.4194 - val_accuracy: 0.7871\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 1.4107 - val_accuracy: 0.7941\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 1.4322 - val_accuracy: 0.7911\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 1.4564 - val_accuracy: 0.7898\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 1.4678 - val_accuracy: 0.7931\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 1.5061 - val_accuracy: 0.7931\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 1.5265 - val_accuracy: 0.7964\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.5430 - val_accuracy: 0.8004\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 1.5629 - val_accuracy: 0.7947\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 1.5936 - val_accuracy: 0.7901\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.5671 - val_accuracy: 0.7921\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 1.5985 - val_accuracy: 0.7861\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.6163 - val_accuracy: 0.7891\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.6174 - val_accuracy: 0.7898\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 1.6312 - val_accuracy: 0.7884\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 1.6381 - val_accuracy: 0.7868\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 1.6606 - val_accuracy: 0.7888\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 1.6537 - val_accuracy: 0.7934\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 1.6871 - val_accuracy: 0.7848\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 1.6894 - val_accuracy: 0.7894\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 1.6982 - val_accuracy: 0.7898\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 1.7155 - val_accuracy: 0.7871\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 1.7335 - val_accuracy: 0.7914\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.7386 - val_accuracy: 0.7884\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 1.7367 - val_accuracy: 0.7911\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.7365 - val_accuracy: 0.7878\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 1.7301 - val_accuracy: 0.7924\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.7363 - val_accuracy: 0.7911\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 1.7555 - val_accuracy: 0.7898\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 1.7444 - val_accuracy: 0.7904\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 1.7575 - val_accuracy: 0.7891\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.7721 - val_accuracy: 0.7878\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 1.7704 - val_accuracy: 0.7917\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 1.7700 - val_accuracy: 0.7951\n",
      "Epoch 77/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 1.7511 - val_accuracy: 0.7904\n",
      "Epoch 78/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.7697 - val_accuracy: 0.7924\n",
      "Epoch 79/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 1.7797 - val_accuracy: 0.7921\n",
      "Epoch 80/300\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 1.7779 - val_accuracy: 0.7898\n",
      "Epoch 81/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.8029 - val_accuracy: 0.7861\n",
      "Epoch 82/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.7957 - val_accuracy: 0.7871\n",
      "Epoch 83/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 1.7905 - val_accuracy: 0.7901\n",
      "Epoch 84/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 1.7921 - val_accuracy: 0.7934\n",
      "Epoch 85/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 1.8111 - val_accuracy: 0.7914\n",
      "./Results/Fold_2/Models/20241002-1448\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 82s 524ms/step - loss: 1.0789 - accuracy: 0.5319 - val_loss: 0.8107 - val_accuracy: 0.6534\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.8182 - accuracy: 0.6546 - val_loss: 0.7383 - val_accuracy: 0.6810\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.7418 - accuracy: 0.6869 - val_loss: 0.6718 - val_accuracy: 0.7186\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.6717 - accuracy: 0.7230 - val_loss: 0.6354 - val_accuracy: 0.7455\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.6107 - accuracy: 0.7605 - val_loss: 0.5708 - val_accuracy: 0.7771\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.5644 - accuracy: 0.7839 - val_loss: 0.5435 - val_accuracy: 0.7848\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.5422 - accuracy: 0.7943 - val_loss: 0.5235 - val_accuracy: 0.8017\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.5023 - accuracy: 0.8107 - val_loss: 0.5194 - val_accuracy: 0.8110\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.4867 - accuracy: 0.8211 - val_loss: 0.4894 - val_accuracy: 0.8177\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.4565 - accuracy: 0.8322 - val_loss: 0.5027 - val_accuracy: 0.8137\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4348 - accuracy: 0.8425 - val_loss: 0.4956 - val_accuracy: 0.8100\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.4163 - accuracy: 0.8472 - val_loss: 0.4918 - val_accuracy: 0.8170\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.3893 - accuracy: 0.8622 - val_loss: 0.5137 - val_accuracy: 0.8047\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.3647 - accuracy: 0.8734 - val_loss: 0.5334 - val_accuracy: 0.8100\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.3442 - accuracy: 0.8782 - val_loss: 0.5237 - val_accuracy: 0.8194\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.3149 - accuracy: 0.8908 - val_loss: 0.5349 - val_accuracy: 0.8127\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.2857 - accuracy: 0.9042 - val_loss: 0.5662 - val_accuracy: 0.8057\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2646 - accuracy: 0.9125 - val_loss: 0.5853 - val_accuracy: 0.8127\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.2355 - accuracy: 0.9212 - val_loss: 0.6357 - val_accuracy: 0.8067\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2128 - accuracy: 0.9288 - val_loss: 0.6540 - val_accuracy: 0.8031\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.2036 - accuracy: 0.9318 - val_loss: 0.6651 - val_accuracy: 0.8107\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.1875 - accuracy: 0.9394 - val_loss: 0.7037 - val_accuracy: 0.8120\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.1629 - accuracy: 0.9496 - val_loss: 0.7167 - val_accuracy: 0.8117\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.1443 - accuracy: 0.9544 - val_loss: 0.7593 - val_accuracy: 0.8090\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.1236 - accuracy: 0.9609 - val_loss: 0.8122 - val_accuracy: 0.8011\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1181 - accuracy: 0.9623 - val_loss: 0.8527 - val_accuracy: 0.8041\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.1049 - accuracy: 0.9676 - val_loss: 0.8499 - val_accuracy: 0.8047\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0945 - accuracy: 0.9716 - val_loss: 0.9127 - val_accuracy: 0.8034\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0799 - accuracy: 0.9753 - val_loss: 0.9411 - val_accuracy: 0.8064\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0763 - accuracy: 0.9759 - val_loss: 0.9576 - val_accuracy: 0.8094\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.0797 - accuracy: 0.9737 - val_loss: 0.9775 - val_accuracy: 0.8077\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0718 - accuracy: 0.9770 - val_loss: 0.9917 - val_accuracy: 0.8017\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0678 - accuracy: 0.9778 - val_loss: 0.9924 - val_accuracy: 0.8084\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0583 - accuracy: 0.9805 - val_loss: 1.0167 - val_accuracy: 0.8110\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 1.0619 - val_accuracy: 0.8084\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 1.1256 - val_accuracy: 0.8057\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 1.1618 - val_accuracy: 0.8117\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 1.1599 - val_accuracy: 0.8114\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 1.2214 - val_accuracy: 0.8047\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 1.2210 - val_accuracy: 0.8024\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 1.2668 - val_accuracy: 0.8054\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 1.3046 - val_accuracy: 0.8037\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 1.3087 - val_accuracy: 0.8041\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 1.3032 - val_accuracy: 0.8014\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 1.3408 - val_accuracy: 0.8037\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 1.3587 - val_accuracy: 0.8047\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.3650 - val_accuracy: 0.8014\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 1.3618 - val_accuracy: 0.8104\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 1.4263 - val_accuracy: 0.7997\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 1.4001 - val_accuracy: 0.8001\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 1.3911 - val_accuracy: 0.8097\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 1.4196 - val_accuracy: 0.8074\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 1.4360 - val_accuracy: 0.8064\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 1.4645 - val_accuracy: 0.7981\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 1.4588 - val_accuracy: 0.8061\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 1.4937 - val_accuracy: 0.8027\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 1.4942 - val_accuracy: 0.8031\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.5279 - val_accuracy: 0.7987\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 1.5373 - val_accuracy: 0.8007\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 1.5301 - val_accuracy: 0.8061\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.5408 - val_accuracy: 0.8087\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.5625 - val_accuracy: 0.8067\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 1.5664 - val_accuracy: 0.8064\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.5669 - val_accuracy: 0.8051\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.5488 - val_accuracy: 0.8071\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 1.5866 - val_accuracy: 0.8057\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.5754 - val_accuracy: 0.8074\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.5742 - val_accuracy: 0.8054\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 1.5996 - val_accuracy: 0.8027\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 1.6137 - val_accuracy: 0.8071\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 1.6083 - val_accuracy: 0.8037\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.6546 - val_accuracy: 0.8061\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.6537 - val_accuracy: 0.8064\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.6440 - val_accuracy: 0.8054\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 1.6458 - val_accuracy: 0.8031\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.6617 - val_accuracy: 0.8024\n",
      "Epoch 77/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.6723 - val_accuracy: 0.7984\n",
      "Epoch 78/300\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.6637 - val_accuracy: 0.8011\n",
      "Epoch 79/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.6651 - val_accuracy: 0.8037\n",
      "Epoch 80/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 1.6630 - val_accuracy: 0.8011\n",
      "Epoch 81/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.6907 - val_accuracy: 0.7974\n",
      "Epoch 82/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 1.7033 - val_accuracy: 0.7977\n",
      "Epoch 83/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.6991 - val_accuracy: 0.7994\n",
      "Epoch 84/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 1.6917 - val_accuracy: 0.8044\n",
      "Epoch 85/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.7035 - val_accuracy: 0.8027\n",
      "Epoch 86/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.7007 - val_accuracy: 0.8001\n",
      "./Results/Fold_3/Models/20241002-1455\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 89s 662ms/step - loss: 1.0824 - accuracy: 0.5348 - val_loss: 0.9079 - val_accuracy: 0.5882\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.8920 - accuracy: 0.5899 - val_loss: 0.7789 - val_accuracy: 0.6510\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.7762 - accuracy: 0.6729 - val_loss: 0.7082 - val_accuracy: 0.6883\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.7012 - accuracy: 0.7122 - val_loss: 0.6691 - val_accuracy: 0.7192\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.6364 - accuracy: 0.7496 - val_loss: 0.5821 - val_accuracy: 0.7721\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5856 - accuracy: 0.7766 - val_loss: 0.5617 - val_accuracy: 0.7764\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.5507 - accuracy: 0.7935 - val_loss: 0.5214 - val_accuracy: 0.8021\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.5087 - accuracy: 0.8115 - val_loss: 0.5366 - val_accuracy: 0.7898\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4834 - accuracy: 0.8190 - val_loss: 0.5072 - val_accuracy: 0.8137\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.4619 - accuracy: 0.8307 - val_loss: 0.5142 - val_accuracy: 0.8027\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.4375 - accuracy: 0.8430 - val_loss: 0.5190 - val_accuracy: 0.8071\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.4169 - accuracy: 0.8528 - val_loss: 0.5475 - val_accuracy: 0.8007\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.3913 - accuracy: 0.8591 - val_loss: 0.5523 - val_accuracy: 0.7981\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.3613 - accuracy: 0.8726 - val_loss: 0.5582 - val_accuracy: 0.8017\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.3441 - accuracy: 0.8810 - val_loss: 0.5527 - val_accuracy: 0.8064\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.3067 - accuracy: 0.8960 - val_loss: 0.6086 - val_accuracy: 0.7984\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2876 - accuracy: 0.9024 - val_loss: 0.6051 - val_accuracy: 0.8011\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.2690 - accuracy: 0.9068 - val_loss: 0.6280 - val_accuracy: 0.8051\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.2342 - accuracy: 0.9227 - val_loss: 0.7076 - val_accuracy: 0.7927\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.2087 - accuracy: 0.9316 - val_loss: 0.7276 - val_accuracy: 0.7997\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.1879 - accuracy: 0.9380 - val_loss: 0.7468 - val_accuracy: 0.7981\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.1766 - accuracy: 0.9417 - val_loss: 0.8043 - val_accuracy: 0.7964\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.1562 - accuracy: 0.9504 - val_loss: 0.8506 - val_accuracy: 0.7914\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.1417 - accuracy: 0.9542 - val_loss: 0.8655 - val_accuracy: 0.7944\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.1218 - accuracy: 0.9613 - val_loss: 0.9460 - val_accuracy: 0.7937\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.1064 - accuracy: 0.9658 - val_loss: 0.9696 - val_accuracy: 0.7947\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 0.9918 - val_accuracy: 0.7994\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0890 - accuracy: 0.9709 - val_loss: 1.0482 - val_accuracy: 0.7971\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 1.0951 - val_accuracy: 0.7984\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0725 - accuracy: 0.9770 - val_loss: 1.1437 - val_accuracy: 0.7937\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0650 - accuracy: 0.9785 - val_loss: 1.1478 - val_accuracy: 0.7894\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0611 - accuracy: 0.9809 - val_loss: 1.2190 - val_accuracy: 0.7964\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0548 - accuracy: 0.9838 - val_loss: 1.2479 - val_accuracy: 0.7944\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 1.3012 - val_accuracy: 0.7951\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 1.2855 - val_accuracy: 0.7891\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 1.3531 - val_accuracy: 0.7831\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 1.3820 - val_accuracy: 0.7868\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 1.3954 - val_accuracy: 0.7844\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 1.4066 - val_accuracy: 0.7924\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 1.4129 - val_accuracy: 0.7991\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 1.4821 - val_accuracy: 0.7911\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 1.4897 - val_accuracy: 0.7884\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 1.5155 - val_accuracy: 0.7871\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 1.5436 - val_accuracy: 0.7861\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 1.5276 - val_accuracy: 0.7871\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.5699 - val_accuracy: 0.7924\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 1.5910 - val_accuracy: 0.7904\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 1.6134 - val_accuracy: 0.7888\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 1.6236 - val_accuracy: 0.7854\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 1.6150 - val_accuracy: 0.7851\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 1.6621 - val_accuracy: 0.7908\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 1.6723 - val_accuracy: 0.7881\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 1.6909 - val_accuracy: 0.7908\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 1.7139 - val_accuracy: 0.7881\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 1.6980 - val_accuracy: 0.7927\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 1.7369 - val_accuracy: 0.7874\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.7394 - val_accuracy: 0.7868\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 1.7676 - val_accuracy: 0.7874\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 1.7712 - val_accuracy: 0.7884\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 1.7602 - val_accuracy: 0.7908\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 1.7903 - val_accuracy: 0.7904\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.7900 - val_accuracy: 0.7898\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.8029 - val_accuracy: 0.7888\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 1.8142 - val_accuracy: 0.7884\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.8378 - val_accuracy: 0.7874\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 1.8427 - val_accuracy: 0.7891\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.8449 - val_accuracy: 0.7884\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.8619 - val_accuracy: 0.7911\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.8918 - val_accuracy: 0.7858\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 1.8689 - val_accuracy: 0.7874\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.8870 - val_accuracy: 0.7848\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 1.9065 - val_accuracy: 0.7831\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.8963 - val_accuracy: 0.7824\n",
      "./Results/Fold_4/Models/20241002-1501\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 91s 717ms/step - loss: 1.0713 - accuracy: 0.5227 - val_loss: 0.8658 - val_accuracy: 0.5987\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.8783 - accuracy: 0.5996 - val_loss: 0.7755 - val_accuracy: 0.6542\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.7750 - accuracy: 0.6735 - val_loss: 0.7047 - val_accuracy: 0.6975\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.7008 - accuracy: 0.7106 - val_loss: 0.6560 - val_accuracy: 0.7268\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6330 - accuracy: 0.7533 - val_loss: 0.6019 - val_accuracy: 0.7607\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.5828 - accuracy: 0.7788 - val_loss: 0.5823 - val_accuracy: 0.7587\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.5483 - accuracy: 0.7894 - val_loss: 0.5398 - val_accuracy: 0.7930\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.5253 - accuracy: 0.8061 - val_loss: 0.5515 - val_accuracy: 0.7870\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.4950 - accuracy: 0.8167 - val_loss: 0.5362 - val_accuracy: 0.7913\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4674 - accuracy: 0.8264 - val_loss: 0.5154 - val_accuracy: 0.8043\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.4629 - accuracy: 0.8300 - val_loss: 0.5196 - val_accuracy: 0.8037\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.4249 - accuracy: 0.8449 - val_loss: 0.5127 - val_accuracy: 0.8133\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.3907 - accuracy: 0.8612 - val_loss: 0.5552 - val_accuracy: 0.8013\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.3740 - accuracy: 0.8661 - val_loss: 0.5327 - val_accuracy: 0.8153\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.3484 - accuracy: 0.8787 - val_loss: 0.5205 - val_accuracy: 0.8196\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.3262 - accuracy: 0.8872 - val_loss: 0.5660 - val_accuracy: 0.8146\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.2897 - accuracy: 0.9013 - val_loss: 0.5995 - val_accuracy: 0.8106\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.2719 - accuracy: 0.9087 - val_loss: 0.6220 - val_accuracy: 0.8097\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.2538 - accuracy: 0.9152 - val_loss: 0.6291 - val_accuracy: 0.8103\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.2281 - accuracy: 0.9228 - val_loss: 0.6726 - val_accuracy: 0.8020\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.2071 - accuracy: 0.9325 - val_loss: 0.7164 - val_accuracy: 0.7970\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.1854 - accuracy: 0.9405 - val_loss: 0.7169 - val_accuracy: 0.8133\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.1508 - accuracy: 0.9526 - val_loss: 0.8027 - val_accuracy: 0.8060\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1384 - accuracy: 0.9557 - val_loss: 0.7919 - val_accuracy: 0.8100\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.1361 - accuracy: 0.9555 - val_loss: 0.8444 - val_accuracy: 0.7967\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.1157 - accuracy: 0.9619 - val_loss: 0.8893 - val_accuracy: 0.8050\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0979 - accuracy: 0.9675 - val_loss: 0.9302 - val_accuracy: 0.8047\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0924 - accuracy: 0.9707 - val_loss: 0.9596 - val_accuracy: 0.8050\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0763 - accuracy: 0.9750 - val_loss: 1.0152 - val_accuracy: 0.8030\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0683 - accuracy: 0.9801 - val_loss: 1.0569 - val_accuracy: 0.7987\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 1.0576 - val_accuracy: 0.8063\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0597 - accuracy: 0.9807 - val_loss: 1.1508 - val_accuracy: 0.8020\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 1.1604 - val_accuracy: 0.8033\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 1.2137 - val_accuracy: 0.7997\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 1.2199 - val_accuracy: 0.8003\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 1.3002 - val_accuracy: 0.7930\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0328 - accuracy: 0.9905 - val_loss: 1.3056 - val_accuracy: 0.7983\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 1.3213 - val_accuracy: 0.7950\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 1.2971 - val_accuracy: 0.8057\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 1.3096 - val_accuracy: 0.7997\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 1.3508 - val_accuracy: 0.8013\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.3620 - val_accuracy: 0.8023\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 1.3632 - val_accuracy: 0.7970\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 1.4114 - val_accuracy: 0.7970\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 1.4299 - val_accuracy: 0.7940\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 1.4181 - val_accuracy: 0.8030\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 1.4578 - val_accuracy: 0.8013\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.4759 - val_accuracy: 0.7927\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 1.5070 - val_accuracy: 0.7980\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 1.5408 - val_accuracy: 0.7947\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 1.5580 - val_accuracy: 0.8010\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.5599 - val_accuracy: 0.7983\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 1.5621 - val_accuracy: 0.7930\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.5797 - val_accuracy: 0.8023\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.6022 - val_accuracy: 0.7977\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 1.6191 - val_accuracy: 0.7937\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 1.6012 - val_accuracy: 0.7977\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 1.6011 - val_accuracy: 0.7983\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 1.6360 - val_accuracy: 0.7967\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 1.6117 - val_accuracy: 0.7980\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 1.6484 - val_accuracy: 0.7983\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 1.6624 - val_accuracy: 0.7920\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.6715 - val_accuracy: 0.7903\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.6661 - val_accuracy: 0.7920\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.6834 - val_accuracy: 0.7907\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 1.6960 - val_accuracy: 0.7927\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 1.7156 - val_accuracy: 0.7973\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.7348 - val_accuracy: 0.7960\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 1.7350 - val_accuracy: 0.8003\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 1.7293 - val_accuracy: 0.8000\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 1.7349 - val_accuracy: 0.7987\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 1.7392 - val_accuracy: 0.7977\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 1.7648 - val_accuracy: 0.7973\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.7526 - val_accuracy: 0.7937\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 1.7555 - val_accuracy: 0.7977\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.7560 - val_accuracy: 0.7953\n",
      "Epoch 77/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 1.7648 - val_accuracy: 0.7963\n",
      "Epoch 78/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 1.7726 - val_accuracy: 0.7943\n",
      "Epoch 79/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 1.7592 - val_accuracy: 0.7960\n",
      "Epoch 80/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 1.7803 - val_accuracy: 0.7973\n",
      "Epoch 81/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 1.8143 - val_accuracy: 0.7937\n",
      "Epoch 82/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 1.8039 - val_accuracy: 0.7953\n",
      "Epoch 83/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.7999 - val_accuracy: 0.7967\n",
      "Epoch 84/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 1.8106 - val_accuracy: 0.7940\n",
      "Epoch 85/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 1.8215 - val_accuracy: 0.7940\n",
      "Epoch 86/300\n",
      "36/36 [==============================] - 4s 94ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 1.8155 - val_accuracy: 0.7933\n",
      "Epoch 87/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.8264 - val_accuracy: 0.7947\n",
      "./Results/Fold_5/Models/20241002-1509\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 89s 756ms/step - loss: 1.0945 - accuracy: 0.5256 - val_loss: 0.8522 - val_accuracy: 0.5993\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.8407 - accuracy: 0.6295 - val_loss: 0.7407 - val_accuracy: 0.6705\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.7549 - accuracy: 0.6798 - val_loss: 0.6770 - val_accuracy: 0.7075\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.6899 - accuracy: 0.7099 - val_loss: 0.6514 - val_accuracy: 0.7344\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6236 - accuracy: 0.7539 - val_loss: 0.6058 - val_accuracy: 0.7524\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.5758 - accuracy: 0.7757 - val_loss: 0.5880 - val_accuracy: 0.7681\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5432 - accuracy: 0.7937 - val_loss: 0.5497 - val_accuracy: 0.7877\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.5007 - accuracy: 0.8152 - val_loss: 0.5285 - val_accuracy: 0.8057\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.4759 - accuracy: 0.8263 - val_loss: 0.5228 - val_accuracy: 0.8050\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.4551 - accuracy: 0.8336 - val_loss: 0.5379 - val_accuracy: 0.7980\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.4370 - accuracy: 0.8419 - val_loss: 0.5486 - val_accuracy: 0.7910\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.4042 - accuracy: 0.8546 - val_loss: 0.5386 - val_accuracy: 0.8050\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.3731 - accuracy: 0.8682 - val_loss: 0.5406 - val_accuracy: 0.8017\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.3484 - accuracy: 0.8797 - val_loss: 0.5673 - val_accuracy: 0.8010\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.3191 - accuracy: 0.8892 - val_loss: 0.5838 - val_accuracy: 0.8030\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.2940 - accuracy: 0.9008 - val_loss: 0.6426 - val_accuracy: 0.7940\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.2839 - accuracy: 0.9039 - val_loss: 0.6038 - val_accuracy: 0.8073\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.2403 - accuracy: 0.9184 - val_loss: 0.6863 - val_accuracy: 0.8007\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.2246 - accuracy: 0.9252 - val_loss: 0.6789 - val_accuracy: 0.8047\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.1968 - accuracy: 0.9357 - val_loss: 0.7463 - val_accuracy: 0.7927\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.1818 - accuracy: 0.9398 - val_loss: 0.7925 - val_accuracy: 0.7937\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.1609 - accuracy: 0.9492 - val_loss: 0.8194 - val_accuracy: 0.7923\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.1438 - accuracy: 0.9533 - val_loss: 0.8304 - val_accuracy: 0.8053\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.1197 - accuracy: 0.9618 - val_loss: 0.9283 - val_accuracy: 0.7960\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.1103 - accuracy: 0.9644 - val_loss: 0.9536 - val_accuracy: 0.7960\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.1199 - accuracy: 0.9611 - val_loss: 0.9460 - val_accuracy: 0.7930\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 1.0159 - val_accuracy: 0.7973\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0807 - accuracy: 0.9736 - val_loss: 1.0628 - val_accuracy: 0.7973\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0854 - accuracy: 0.9718 - val_loss: 1.0715 - val_accuracy: 0.7897\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.0679 - accuracy: 0.9783 - val_loss: 1.1458 - val_accuracy: 0.7923\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 1.1756 - val_accuracy: 0.7930\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0543 - accuracy: 0.9830 - val_loss: 1.2363 - val_accuracy: 0.7913\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 1.2055 - val_accuracy: 0.7963\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 1.2682 - val_accuracy: 0.7963\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 1.3322 - val_accuracy: 0.7877\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 1.3469 - val_accuracy: 0.7913\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 1.3771 - val_accuracy: 0.7860\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0349 - accuracy: 0.9906 - val_loss: 1.3562 - val_accuracy: 0.7880\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 1.3986 - val_accuracy: 0.7923\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 1.4469 - val_accuracy: 0.7950\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 1.4434 - val_accuracy: 0.7933\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 1.4939 - val_accuracy: 0.7923\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 1.5475 - val_accuracy: 0.7900\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 1.5427 - val_accuracy: 0.7857\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 1.5251 - val_accuracy: 0.7877\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 1.5621 - val_accuracy: 0.7880\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 1.5960 - val_accuracy: 0.7957\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 1.6147 - val_accuracy: 0.7937\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 1.6224 - val_accuracy: 0.7903\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 1.6533 - val_accuracy: 0.7880\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 1.6678 - val_accuracy: 0.7903\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 1.7159 - val_accuracy: 0.7857\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 1.6953 - val_accuracy: 0.7917\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.7057 - val_accuracy: 0.7910\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 1.7357 - val_accuracy: 0.7894\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 1.7157 - val_accuracy: 0.7897\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.7258 - val_accuracy: 0.7913\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.7329 - val_accuracy: 0.7897\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.7539 - val_accuracy: 0.7897\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.7493 - val_accuracy: 0.7894\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.7553 - val_accuracy: 0.7900\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 1.7602 - val_accuracy: 0.7913\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 1.7744 - val_accuracy: 0.7930\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.7775 - val_accuracy: 0.7894\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 1.8207 - val_accuracy: 0.7864\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 1.8461 - val_accuracy: 0.7840\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.8312 - val_accuracy: 0.7870\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.8167 - val_accuracy: 0.7894\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 1.7956 - val_accuracy: 0.7884\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.8301 - val_accuracy: 0.7887\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 1.8308 - val_accuracy: 0.7907\n",
      "./Results/Fold_6/Models/20241002-1516\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 85s 664ms/step - loss: 1.0923 - accuracy: 0.5261 - val_loss: 0.8783 - val_accuracy: 0.5754\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.8624 - accuracy: 0.6196 - val_loss: 0.7638 - val_accuracy: 0.6639\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.7596 - accuracy: 0.6808 - val_loss: 0.6990 - val_accuracy: 0.7035\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.6916 - accuracy: 0.7137 - val_loss: 0.7258 - val_accuracy: 0.6839\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.6364 - accuracy: 0.7500 - val_loss: 0.5837 - val_accuracy: 0.7681\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5802 - accuracy: 0.7748 - val_loss: 0.5408 - val_accuracy: 0.7900\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5374 - accuracy: 0.7981 - val_loss: 0.5373 - val_accuracy: 0.7933\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.5022 - accuracy: 0.8131 - val_loss: 0.5113 - val_accuracy: 0.8013\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.4788 - accuracy: 0.8243 - val_loss: 0.5051 - val_accuracy: 0.8050\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.4589 - accuracy: 0.8351 - val_loss: 0.5026 - val_accuracy: 0.8093\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.4391 - accuracy: 0.8397 - val_loss: 0.4999 - val_accuracy: 0.8203\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.4024 - accuracy: 0.8534 - val_loss: 0.4903 - val_accuracy: 0.8170\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.3784 - accuracy: 0.8656 - val_loss: 0.5001 - val_accuracy: 0.8263\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.3668 - accuracy: 0.8705 - val_loss: 0.5315 - val_accuracy: 0.8140\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.3437 - accuracy: 0.8788 - val_loss: 0.5053 - val_accuracy: 0.8213\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.3085 - accuracy: 0.8972 - val_loss: 0.5385 - val_accuracy: 0.8153\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.2830 - accuracy: 0.9053 - val_loss: 0.5685 - val_accuracy: 0.8176\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2698 - accuracy: 0.9112 - val_loss: 0.5765 - val_accuracy: 0.8120\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.2409 - accuracy: 0.9217 - val_loss: 0.6278 - val_accuracy: 0.8017\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.2293 - accuracy: 0.9233 - val_loss: 0.6287 - val_accuracy: 0.8123\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.1952 - accuracy: 0.9367 - val_loss: 0.6883 - val_accuracy: 0.8106\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1896 - accuracy: 0.9405 - val_loss: 0.7006 - val_accuracy: 0.8097\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.1555 - accuracy: 0.9514 - val_loss: 0.7672 - val_accuracy: 0.8073\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1455 - accuracy: 0.9556 - val_loss: 0.7734 - val_accuracy: 0.8156\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1214 - accuracy: 0.9637 - val_loss: 0.8240 - val_accuracy: 0.8116\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.1154 - accuracy: 0.9645 - val_loss: 0.8843 - val_accuracy: 0.7950\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0984 - accuracy: 0.9697 - val_loss: 0.9188 - val_accuracy: 0.7973\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0934 - accuracy: 0.9719 - val_loss: 0.9822 - val_accuracy: 0.7967\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0852 - accuracy: 0.9733 - val_loss: 0.9922 - val_accuracy: 0.8010\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0769 - accuracy: 0.9767 - val_loss: 1.0105 - val_accuracy: 0.8020\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0731 - accuracy: 0.9761 - val_loss: 1.0593 - val_accuracy: 0.7910\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 1.0653 - val_accuracy: 0.7950\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 1.0705 - val_accuracy: 0.8033\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 1.1345 - val_accuracy: 0.7990\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 1.1603 - val_accuracy: 0.7957\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 1.2241 - val_accuracy: 0.7987\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 1.2887 - val_accuracy: 0.7903\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 1.3460 - val_accuracy: 0.7864\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 1.3596 - val_accuracy: 0.7930\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0238 - accuracy: 0.9935 - val_loss: 1.3634 - val_accuracy: 0.7884\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 1.3972 - val_accuracy: 0.8010\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 1.4424 - val_accuracy: 0.7920\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 1.4709 - val_accuracy: 0.7860\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 1.5007 - val_accuracy: 0.7890\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 1.5018 - val_accuracy: 0.7880\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 1.4946 - val_accuracy: 0.7903\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 1.4593 - val_accuracy: 0.7927\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 1.5048 - val_accuracy: 0.7950\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 1.5318 - val_accuracy: 0.7923\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 1.4992 - val_accuracy: 0.7980\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 1.5615 - val_accuracy: 0.7943\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.5381 - val_accuracy: 0.7963\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 1.5970 - val_accuracy: 0.7913\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.6140 - val_accuracy: 0.7887\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 1.6183 - val_accuracy: 0.7967\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 1.6604 - val_accuracy: 0.7913\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 1.6552 - val_accuracy: 0.7854\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 1.6585 - val_accuracy: 0.7943\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.6439 - val_accuracy: 0.7953\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 1.6914 - val_accuracy: 0.7970\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.6914 - val_accuracy: 0.7930\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 1.7215 - val_accuracy: 0.7903\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 1.7090 - val_accuracy: 0.7953\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 1.7388 - val_accuracy: 0.7903\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.7153 - val_accuracy: 0.7973\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.6992 - val_accuracy: 0.7943\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.7049 - val_accuracy: 0.7927\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 1.7169 - val_accuracy: 0.7917\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.7572 - val_accuracy: 0.7917\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 1.7640 - val_accuracy: 0.7897\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.7668 - val_accuracy: 0.7887\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.7752 - val_accuracy: 0.7864\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 1.7678 - val_accuracy: 0.7880\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 1.7865 - val_accuracy: 0.7897\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 1.7792 - val_accuracy: 0.7894\n",
      "./Results/Fold_7/Models/20241002-1523\n",
      "Epoch 1/300\n",
      "36/36 [==============================] - 78s 679ms/step - loss: 1.0655 - accuracy: 0.5340 - val_loss: 0.8732 - val_accuracy: 0.5983\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.8335 - accuracy: 0.6363 - val_loss: 0.7590 - val_accuracy: 0.6699\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.7525 - accuracy: 0.6804 - val_loss: 0.6889 - val_accuracy: 0.7095\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.6899 - accuracy: 0.7149 - val_loss: 0.6169 - val_accuracy: 0.7468\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6278 - accuracy: 0.7528 - val_loss: 0.5966 - val_accuracy: 0.7591\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.5824 - accuracy: 0.7779 - val_loss: 0.5559 - val_accuracy: 0.7867\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.5484 - accuracy: 0.7967 - val_loss: 0.5343 - val_accuracy: 0.7923\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.5081 - accuracy: 0.8145 - val_loss: 0.5282 - val_accuracy: 0.8033\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.4929 - accuracy: 0.8187 - val_loss: 0.5218 - val_accuracy: 0.8050\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.4586 - accuracy: 0.8331 - val_loss: 0.5064 - val_accuracy: 0.8077\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.4288 - accuracy: 0.8451 - val_loss: 0.5411 - val_accuracy: 0.7993\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.4085 - accuracy: 0.8524 - val_loss: 0.5203 - val_accuracy: 0.8150\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.3808 - accuracy: 0.8660 - val_loss: 0.5235 - val_accuracy: 0.8120\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.3574 - accuracy: 0.8759 - val_loss: 0.5208 - val_accuracy: 0.8163\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.3260 - accuracy: 0.8894 - val_loss: 0.5504 - val_accuracy: 0.8110\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.2991 - accuracy: 0.8994 - val_loss: 0.5882 - val_accuracy: 0.8126\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.2820 - accuracy: 0.9076 - val_loss: 0.5986 - val_accuracy: 0.8170\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.2592 - accuracy: 0.9141 - val_loss: 0.6309 - val_accuracy: 0.8126\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.2214 - accuracy: 0.9264 - val_loss: 0.6725 - val_accuracy: 0.8073\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.2080 - accuracy: 0.9330 - val_loss: 0.6820 - val_accuracy: 0.8110\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.1880 - accuracy: 0.9375 - val_loss: 0.7184 - val_accuracy: 0.8063\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.1608 - accuracy: 0.9471 - val_loss: 0.7541 - val_accuracy: 0.8027\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.1425 - accuracy: 0.9531 - val_loss: 0.7896 - val_accuracy: 0.8067\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.1275 - accuracy: 0.9601 - val_loss: 0.8624 - val_accuracy: 0.7973\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.1185 - accuracy: 0.9616 - val_loss: 0.8750 - val_accuracy: 0.7943\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0988 - accuracy: 0.9683 - val_loss: 0.9005 - val_accuracy: 0.8060\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0857 - accuracy: 0.9734 - val_loss: 0.9757 - val_accuracy: 0.8020\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0804 - accuracy: 0.9740 - val_loss: 1.0236 - val_accuracy: 0.7950\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0852 - accuracy: 0.9729 - val_loss: 1.0285 - val_accuracy: 0.7933\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 1.0133 - val_accuracy: 0.8040\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 1.0855 - val_accuracy: 0.7910\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 1.1277 - val_accuracy: 0.7950\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 1.1728 - val_accuracy: 0.7967\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 1.2160 - val_accuracy: 0.7933\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 1.1897 - val_accuracy: 0.7997\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 1.2492 - val_accuracy: 0.8003\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 1.2774 - val_accuracy: 0.7957\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0242 - accuracy: 0.9940 - val_loss: 1.3112 - val_accuracy: 0.7977\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 1.3556 - val_accuracy: 0.7950\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 1.3416 - val_accuracy: 0.7923\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 1.3801 - val_accuracy: 0.7983\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 1.3857 - val_accuracy: 0.7963\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 1.4089 - val_accuracy: 0.7957\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 1.4299 - val_accuracy: 0.7897\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 1.4588 - val_accuracy: 0.7963\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 1.4487 - val_accuracy: 0.8023\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 1.5080 - val_accuracy: 0.7950\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 1.4251 - val_accuracy: 0.8037\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 1.4902 - val_accuracy: 0.7940\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 1.5005 - val_accuracy: 0.7977\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.5239 - val_accuracy: 0.7957\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 1.5133 - val_accuracy: 0.7973\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 1.5205 - val_accuracy: 0.7963\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 1.5566 - val_accuracy: 0.7993\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.5517 - val_accuracy: 0.7977\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.5634 - val_accuracy: 0.7977\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 1.5926 - val_accuracy: 0.7947\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 1.5946 - val_accuracy: 0.7933\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 1.6187 - val_accuracy: 0.7927\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.6302 - val_accuracy: 0.7897\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.6454 - val_accuracy: 0.7877\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 1.6544 - val_accuracy: 0.7917\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 1.6685 - val_accuracy: 0.7907\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 1.6774 - val_accuracy: 0.7880\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.6737 - val_accuracy: 0.7937\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 1.6910 - val_accuracy: 0.7854\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 1.6750 - val_accuracy: 0.7917\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 1.6856 - val_accuracy: 0.7913\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 1.6865 - val_accuracy: 0.7910\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 1.6745 - val_accuracy: 0.7923\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.6878 - val_accuracy: 0.7887\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.6692 - val_accuracy: 0.7950\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 1.6662 - val_accuracy: 0.7933\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 1.6817 - val_accuracy: 0.7950\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 1.7164 - val_accuracy: 0.7923\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 1.7237 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "sauces = []\n",
    "for fold in folds:\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Set the fold path\n",
    "    base_dir = fold+'/'\n",
    "    \n",
    "    # Set the save path for this fold. Create folder if needed\n",
    "    path_results_fold = fold.replace('../../02_CreateRecords/'+survey+'/', './').replace('/Folds/', '/Results/')\n",
    "    if not os.path.exists(path_results_fold):\n",
    "        os.mkdir(path_results_fold)    \n",
    "        \n",
    "    train_args_specific['save_dir'] = path_results_fold\n",
    "    train_args_specific['metadata_pre_path'] = base_dir+'metadata_preprocess.json'  \n",
    "    train_args_specific['path_scalers'] =  os.path.join(fold,'scalers.pkl')\n",
    "    # Define the train args\n",
    "    train_args = {**train_args, **train_args_specific}\n",
    "    \n",
    "    train_files = base_dir+'train/*.tfrecord'\n",
    "    val_files = base_dir+'val/*.tfrecord'\n",
    "    test_files = base_dir+'test/*.tfrecord'\n",
    "    \n",
    "    new = multiband.Network()    \n",
    "    new.train(train_args, train_files, val_files, test_files)\n",
    "    # Create the Mixture of Experts model, from the original multiband model\n",
    "    model_base = create_models(new)\n",
    "    model = model_base.creat_split_models(train_args)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='accuracy', **callbacks_args)\n",
    "    # Fit the model to the original data\n",
    "    model.fit(new.dataset_train, validation_data=new.dataset_val, epochs=300,callbacks = [es] )\n",
    "\n",
    "    # Store the alpha coefficients per fold\n",
    "    sauces_ = {i.name:i for i in model.layers if 'Sauce_' in i.name}\n",
    "    scales = {key:tf.nn.softmax(sauces_[key].scale).numpy() for key in sauces_.keys()}\n",
    "    sauces.append(scales)\n",
    "    # Test\n",
    "    dfs = []\n",
    "    for batch in new.dataset_test:\n",
    "        prediction = model(batch[0])\n",
    "        y_pred = prediction['Class'].numpy().argmax(axis=1)\n",
    "        y_pred = [new.trans[i] for i in y_pred]\n",
    "        ID = batch[0]['ID'].numpy()\n",
    "\n",
    "        y_true = batch[1]['Class'].numpy().argmax(axis=1)\n",
    "        y_true = [new.trans[i] for i in y_true]\n",
    "\n",
    "        df = pd.DataFrame(np.array([ID, y_pred, y_true]).transpose(), columns=['ID', 'Class', 'Pred'])\n",
    "        df.ID = df.ID.str.decode('UTF-8')\n",
    "        dfs.append(df)\n",
    "    dfs = pd.concat(dfs, axis=0)\n",
    "    dfs.to_csv(path_results_fold+'/Classification_test.dat', index=False, index_label=False)\n",
    "    \n",
    "pd.DataFrame(sauces).to_csv(path_results_fold+'/sauces.dat', index=False, index_label=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
